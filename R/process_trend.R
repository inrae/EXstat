# Copyright 2021-2023 Louis Héraut (louis.heraut@inrae.fr)*1,
#                     Éric Sauquet (eric.sauquet@inrae.fr)*1
#
# *1   INRAE, France
#
# This file is part of EXstat R package.
#
# EXstat R package is free software: you can redistribute it and/or
# modify it under the terms of the GNU General Public License as
# published by the Free Software Foundation, either version 3 of the
# License, or (at your option) any later version.
#
# EXstat R package is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with EXstat R package.
# If not, see <https://www.gnu.org/licenses/>.


#' @title process_trend
#' @description Analyzes the trend in data using statistical tests and estimation methods.
#'
#' @param dataEX A data frame containing the data to be analyzed.
#' @param metaEX A data frame containing metadata information (optional).
#' @param MK_level The significance level for the Mann-Kendall statistical test.
#' @param timeDep_option The time dependency option to use in the Mann-Kendall test.
#' @param take_not_signif_into_account Flag indicating whether to take into account non-significant trends.
#' @param period_trend A list of periods to consider for trend analysis (optional).
#' @param period_change A list of periods to consider for change analysis (optional).
#' @param exProb The extreme probability threshold for identifying extreme values (optional).
#' @param verbose Flag indicating whether to display verbose output during the analysis.
#' @param ... Additional parameters to be passed to the statistical test and estimation methods.
#'
#' @return A data frame containing the results of the trend analysis.
#'
#' @details The function analyzes the trend in the provided data using statistical tests, such as the Mann-Kendall test, and estimation methods. It computes the trend for each specified period, detects significant trends, estimates other variables related to the trend, and identifies extreme values if metadata information is provided.
#' 
#' @note documentation generated by chatGPT
#' 
#' @examples
#' # Date
#' Start = as.Date("1972-01-01")
#' End = as.Date("2020-12-31")
#' Date = seq.Date(Start, End, by="day")
#' 
#' # Value to analyse
#' set.seed(100)
#' X = seq(1, length(Date))/1e4 + runif(length(Date), -100, 100)
#' X[as.Date("2000-03-01") <= Date & Date <= as.Date("2000-09-30")] = NA
#'
#' # Creation of tibble
#' data = dplyr::tibble(Date=Date, ID="serie A", X=X)
#'
#' # Extraction
#' dataEX = process_extraction(data=data,
#'                             samplePeriod=c("05-01",
#'                                            "11-30"),
#'                             funct=max,
#'                             na.rm=TRUE,
#'                             period=c(as.Date("1990-01-01"),
#'                                      as.Date("2020-12-31")),
#'                             timeStep="year")
#'
#' trendEX = process_trend(data=dataEX)
#' trendEX
#' 
#' @importFrom lubridate is.Date
#' @importFrom dplyr tibble group_by filter summarise bind_rows bind_cols
#'
#' @export
process_trend = function (dataEX,
                          metaEX=NULL,
                          MK_level=0.1,
                          timeDep_option="INDE",
                          # isFDR=FALSE,
                          # FDR_level=0.1,
                          take_not_signif_into_account=TRUE,
                          period_trend=NULL,
                          period_change=NULL,
                          exProb=0.01,
                          verbose=FALSE,
                          ...) {

    tree("TREND ANALYSE", 0, verbose=verbose)
    
    names_save = names(dataEX)
    idValue_save = c()
    for (id in 1:ncol(dataEX)) {
        x = dataEX[[id]]

        if (is.character(x)) {
            idCode_save = id
        } else if (lubridate::is.Date(x)) {
            idDate_save = id
        } else if (is.numeric(x)) {
            if (names_save[id] == "NApct") {
                idNA_save = id
            } else {
                idValue_save = c(idValue_save, id)
            }
        }
    }
    
    names(dataEX)[c(idCode_save, idDate_save, idValue_save)] =
        c("Code", "Date", "Value")



    if (is.null(period_trend)) {
        nPeriod_trend = 1
    } else {
        if (!is.list(period_trend)) {
            period_trend = list(period_trend)
        }
        nPeriod_trend = length(period_trend)
    }

    trendEX = dplyr::tibble()
    
    for (j in 1:nPeriod_trend) {

        if (is.null(period_trend)) {
            dataEX_period = dataEX
        } else {
            period = as.Date(period_trend[[j]])
            if (is.na(period[1])) {
                period[1] = min(dataEX$Date, na.rm=TRUE)
            }
            if (is.na(period[2])) {
                period[2] = max(dataEX$Date, na.rm=TRUE)
            }            
            dataEX_period = dplyr::filter(dataEX,
                                          min(period) <= Date &
                                          Date <= max(period))
        }
        
        tree("Grouping dataEX by code", 1, verbose=verbose)
        # Group dataEX accordingly to group.names
        dataEX_period = dplyr::group_by(dataEX_period, Code)

        tree("Statistical test",
             1, verbose=verbose)

        tree(paste0("Application of the Mann-Kendall statistical test ",
                    "with a level of ",
                    round(MK_level*100), " % and ",
                    timeDep_option, " time dependency option"),
             2, verbose=verbose)
        
        # 1pply function on values accounting for grouping variables
        # 'group.names"
        trendEX_period =
            dplyr::summarise(dataEX_period,
                             GeneralMannKendall_WRAP(
                                 Value,
                                 level=MK_level,
                                 timeDep_option=timeDep_option,
                                 ...))
        
        tree("Estimation of other variable",
             1, end=TRUE, verbose=verbose)
        trendEX_period = get_intercept(dataEX_period, trendEX_period, verbose=verbose)
        trendEX_period = get_period(dataEX_period, trendEX_period, verbose=verbose)

        if (!is.null(metaEX)) {
            trendEX_period =
                dplyr::bind_cols(trendEX_period,
                                 var=names_save[idValue_save])
            trendEX_period =
                get_valueExtremes(dataEX, metaEX,
                                  trendEX_period,
                                  take_not_signif_into_account=
                                      take_not_signif_into_account,
                                  period_change=period_change,
                                  exProb=exProb,
                                  verbose=verbose)
        }
        
        if (nrow(trendEX) == 0) {
            trendEX = trendEX_period
        } else {
            trendEX = dplyr::bind_rows(trendEX,
                                       trendEX_period)
        }
    }




    # if (isFDR) { ### /!\ pas ok
    #     dataEX.final$p.FDR =
    #         fieldSignificance_FDR(dataEX.final$p,
    #                               level=FDR_level)
    # }

    idCode = which(names(trendEX) == "Code")

    names(trendEX)[c(idCode)] =
        names_save[c(idCode_save)]

    return (trendEX)
}



#### 2.3.2. Period of trend analysis _________________________________
#' @title get_period
#' @description Computes the optimal periods for trend analysis based on the data.
#'
#' @param dataEX A data frame containing the data.
#' @param trendEX A data frame containing the results of the trend analysis.
#' @param verbose A logical value indicating whether to display verbose output (default is TRUE).
#'
#' @return A modified data frame with an additional column indicating the optimal periods for trend analysis.
#'
#' @details The function computes the optimal periods for trend analysis based on the data. It calculates the minimum and maximum dates (start and end) for each code group in the data. Then, it creates a new column called "period" that contains a list of the start and end dates for each code group. The function then joins this information with the trend analysis results using the "Code" column.
#'
#' @note documentation generated by chatGPT
#'
#' @importFrom dplyr group_by summarise full_join select
#'
#' @export
get_period = function (dataEX, trendEX, verbose=TRUE) {

    tree("Computing of the optimal periods of trend analysis",
         2, end=TRUE, inEnd=1, verbose=verbose)

    Period = dplyr::summarise(dplyr::group_by(dataEX, Code),
                              start=min(Date, na.rm=TRUE),
                              end=max(Date, na.rm=TRUE),
                              period=list(c(start, end)))
    
    trendEX = dplyr::full_join(trendEX,
                               dplyr::select(Period,
                                             c("Code",
                                               "period")),
                               by="Code")
    return (trendEX)
}

#### 2.3.3. Intercept of trend _______________________________________
#' @title get_intercept
#' @description Computes the intercept of the trend in the data.
#'
#' @param dataEX A data frame containing the data.
#' @param trendEX A data frame containing the results of the trend analysis.
#' @param verbose A logical value indicating whether to display verbose output (default is TRUE).
#'
#' @return A modified data frame with an additional column indicating the intercept of the trend.
#'
#' @details The function computes the intercept of the trend in the data based on the results of the trend analysis. It calculates the mean value of the dependent variable (Value) and the mean time variable (Date) for each code group. Then, it computes the intercept using the formula: b = mu_X - mu_t * a, where mu_X is the mean value, mu_t is the mean time, and a is the slope of the trend.
#'
#' @note documentation generated by chatGPT
#'
#' @importFrom dplyr group_by summarise full_join
#'
#' @export
get_intercept = function (dataEX, trendEX,
                          verbose=TRUE) {

    tree("Computing of the intercept of trend",
         2, inEnd=1, verbose=verbose)
    
    MU_X = dplyr::summarise(dplyr::group_by(dataEX, Code),
                            mu_X=mean(Value, na.rm=TRUE))

    MU_t = dplyr::summarise(dplyr::group_by(dataEX, Code),
                            mu_t=as.numeric(mean(Date,
                                                 na.rm=TRUE)) /
                            mean(as.numeric(diff(Date)), na.rm=TRUE))

    analyse = dplyr::tibble(Code=trendEX$Code,
                            a=trendEX$a,
                            mu_X=MU_X$mu_X,
                            mu_t=MU_t$mu_t)
    
    B = dplyr::summarise(dplyr::group_by(analyse, Code),
                         b=mu_X - mu_t * a)
    
    trendEX = dplyr::full_join(trendEX, B, by="Code")

    return (trendEX)
}


#' @title get_valueExtremes
#' @description Identifies extreme values in the data based on trend analysis.
#'
#' @param dataEX A data frame containing the data.
#' @param metaEX A data frame containing metadata information.
#' @param trendEX A data frame containing the results of the trend analysis.
#' @param take_not_signif_into_account Flag indicating whether to take into account non-significant trends.
#' @param period_change A list of periods to consider for change analysis (optional).
#' @param exProb The extreme probability threshold for identifying extreme values.
#'
#' @return A modified data frame with additional columns indicating extreme values.
#'
#' @details The function identifies extreme values in the data based on the results of the trend analysis. It computes the trend and change for each period and code, and determines extreme values based on the specified extreme probability threshold. If period change analysis is enabled, it also calculates the change between specified periods.
#'
#' @note documentation generated by chatGPT
#'
#' @importFrom dplyr group_by filter select mutate ungroup
#'
#' @export
get_valueExtremes = function (dataEX, metaEX, trendEX,
                              take_not_signif_into_account=TRUE,
                              period_change=NULL,
                              exProb=0.01,
                              verbose=FALSE) {

    tree("Computing extrem values",
         2, end=TRUE, inEnd=1, verbose=verbose)

    Code = levels(factor(dataEX$Code))
    nCode = length(Code)
    # period = unique(trendEX$period)
    var =  levels(factor(trendEX$var))

    dataEX = dplyr::full_join(dataEX,
                              dplyr::select(trendEX,
                                            "Code",
                                            "period"),
                              by="Code")
        
    normalize = metaEX$normalize[metaEX$var == var]
    
    if (normalize) {
        dataEX = dplyr::filter(dataEX,
                               Date >= period[[1]][1] &
                               Date <= period[[1]][2],
                               .by="Code")
        
        dataEX_mean =
            dplyr::summarise(group_by(dataEX, Code),
                             mean=mean(Value, na.rm=TRUE))
        
        trendEX = full_join(trendEX,
                            dataEX_mean,
                            by="Code")
        trendEX$trend = trendEX$a / trendEX$mean
        
    } else {
        trendEX$mean = NA
        trendEX$trend = trendEX$a
    }
        
    if (!is.null(period_change)) {
        nPeriod_change = length(period_change)
        if (nPeriod_change != 2) {
            break
        }

        for (jj in 1:nPeriod_change) {
            dataEX = dataEX[dataEX$Date >=
                            period_change[[jj]][1] &
                            dataEX$Date <=
                            period_change[[jj]][2],]

            dataMean =
                dplyr::summarise(group_by(dataEX, Code),
                                 mean=mean(Value, na.rm=TRUE))
            
            if (jj == 1) {
                dataMean_tmp = dataMean                            
            } else {
                if (normalize) {
                    dataMean$change =
                        (dataMean$mean - dataMean_tmp$mean) /
                        dataMean_tmp$mean
                } else {
                    dataMean$change = dataMean$mean - dataMean_tmp$mean
                }
            }
        }

        dataMean$period_change = list(period_change)
        trendEX = full_join(trendEX,
                            select(dataMean,
                                   c("Code",
                                     "period_change",
                                     "change")),
                            by="Code")
    }
    
    if (!is.null(period_change)) {
        trendEX = dplyr::mutate(trendEX,
                                change_min=quantile(change,
                                                    exProb,
                                                    na.rm=TRUE),
                                change_max=quantile(change,
                                                    1-exProb,
                                                    na.rm=TRUE),
                                .keep="all")
    }

    if (!take_not_signif_into_account) {
        trendEX_trend = trendEX$trend
        trendEX$trend[!trendEX$H] = NA
    }
    
    trendEX = dplyr::mutate(trendEX,
                            trend_min=quantile(trend,
                                               exProb,
                                               na.rm=TRUE),
                            trend_max=quantile(trend,
                                               1-exProb,
                                               na.rm=TRUE),
                            .keep="all")

    if (!take_not_signif_into_account) {
        trendEX$trend = trendEX_trend
    }

    return (trendEX)
}
