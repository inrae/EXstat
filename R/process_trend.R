# Copyright 2021-2023 Louis Héraut (louis.heraut@inrae.fr)*1,
#                     Éric Sauquet (eric.sauquet@inrae.fr)*1
#
# *1   INRAE, France
#
# This file is part of EXstat R package.
#
# EXstat R package is free software: you can redistribute it and/or
# modify it under the terms of the GNU General Public License as
# published by the Free Software Foundation, either version 3 of the
# License, or (at your option) any later version.
#
# EXstat R package is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with EXstat R package.
# If not, see <https://www.gnu.org/licenses/>.


#' @title process_trend
#' @description Analyzes the trend in data using statistical tests and estimation methods.
#'
#' @param dataEX A data frame containing the data to be analyzed.
#' @param metaEX A data frame containing metadata information (optional).
#' @param MK_level The significance level for the Mann-Kendall statistical test.
#' @param time_dependency_option The time dependency option to use in the Mann-Kendall test.
#' @param extreme_take_not_signif_into_account Flag indicating whether to take into account non-significant trends.
#' @param period_trend A list of periods to consider for trend analysis (optional).
#' @param period_change A list of periods to consider for change analysis (optional).
#' @param extreme_prob The extreme probability threshold for identifying extreme values (optional).
#' @param verbose Flag indicating whether to display verbose output during the analysis.
#' @param ... Additional parameters to be passed to the statistical test and estimation methods.
#'
#' @return A data frame containing the results of the trend analysis.
#'
#' @details The function analyzes the trend in the provided data using statistical tests, such as the Mann-Kendall test, and estimation methods. It computes the trend for each specified period, detects significant trends, estimates other variables related to the trend, and identifies extreme values if metadata information is provided.
#' 
#' @note documentation generated by chatGPT
#' 
#' @examples
#' # Date
#' Start = as.Date("1972-01-01")
#' End = as.Date("2020-12-31")
#' Date = seq.Date(Start, End, by="day")
#' 
#' # Variable to analyse
#' set.seed(100)
#' X = seq(1, length(Date))/1e4 + runif(length(Date), -100, 100)
#' X[as.Date("2000-03-01") <= Date & Date <= as.Date("2000-09-30")] = NA
#'
#' # Creation of tibble
#' data = dplyr::tibble(date=Date, ID="serie A", X=X)
#'
#' # Extraction
#' dataEX = process_extraction(data=data,
#'                             sampling_period=c("05-01",
#'                                            "11-30"),
#'                             funct=max,
#'                             na.rm=TRUE,
#'                             period=c(as.Date("1990-01-01"),
#'                                      as.Date("2020-12-31")),
#'                             time_step="year")
#'
#' trendEX = process_trend(data=dataEX)
#' trendEX
#' 
#' @importFrom lubridate is.Date
#' @importFrom dplyr tibble group_by filter summarise bind_rows bind_cols
#'
#' @export
process_trend = function (dataEX,
                          metaEX=NULL,
                          MK_level=0.1,
                          time_dependency_option="INDE",
                          # isFDR=FALSE,
                          # FDR_level=0.1,
                          suffix=NULL,
                          suffix_delimiter="_",
                          extreme_take_not_signif_into_account=TRUE,
                          extreme_take_only_id=NULL,
                          extreme_by_suffix=TRUE,
                          period_trend=NULL,
                          period_change=NULL,
                          extreme_prob=0.01,
                          show_advance_stat=FALSE,
                          dev=FALSE,
                          verbose=FALSE,
                          verbose_stat=FALSE) {

    # check dataEX
    if (!tibble::is_tibble(dataEX)) {
        stop ("'dataEX' is not a tibble from the tibble package. This tibble needs a unique column of objects of class 'Date'")
    }
    
    # check Date column
    if (sum(sapply(dataEX, lubridate::is.Date)) == 0 & !dev) {
        stop ("There needs to be at least one column of objects of class 'Date'.")
    }
    if (sum(sapply(dataEX, lubridate::is.Date)) > 1) {
        stop ("There is more than one column of objects of class 'Date'. There needs to be only one column of objects of class 'Date'.")
    }

    # check numerical columns
    if (sum(sapply(dataEX, is.numeric) |
            sapply(dataEX, is.logical)) < 1) {
        stop ("There needs to be at least one column of class 'numeric' or 'logical'.")
    }
    
    # check character columns
    ID_colnames = names(dplyr::select(dataEX,
                                      dplyr::where(is.character)))
    if (sum(sapply(dataEX, is.character)) == 0 & !dev) {
        if (any(duplicated(
            dataEX[[which(sapply(dataEX,
                                 lubridate::is.Date))]]))) {
            stop ("There is at least one date value that repeat. It seems that either there is more than one time serie (so they need to be identify by a repeted character column for each serie) or there is an error in the format of the date column.")
        } else {
            warning ("There is no character column in order to identify uniquely each time serie. But hence it seems that there is only one time serie, a generic identifier will be add.")
            dataEX$id = "time serie"
        }
    } else if (sum(sapply(dataEX, is.character)) > 1) {
        message ("There is more than one character column. Thus, all the columns will be use to identify uniquely each time serie.")
        dataEX = tidyr::unite(dataEX, "ID",
                              dplyr::where(is.character),
                              sep="_")
    }

    # DATE NA

    if (!dev) {
        # check unicity of Date column for each character identifier
        Date_unicity =
            dplyr::summarise(dplyr::group_by(dataEX,
                                             get(names(dataEX)[sapply(dataEX, is.character)])),
                             n=sum(duplicated(get(names(dataEX)[sapply(dataEX, lubridate::is.Date)]))))
        if (any(Date_unicity$n > 0)) {
            stop (paste0("There is at least one duplicated date in time serie(s) named '",
                         paste0(Date_unicity[[1]][Date_unicity$n > 0],
                                collapse=", "), "'."))
        }
    }
    
    # # check continuity of Date column for each character identifier
    # Date_continuity =
    #     dplyr::summarise(dplyr::group_by(dplyr::arrange(dataEX, get(names(dataEX)[sapply(dataEX, lubridate::is.Date)])),
    #                                      get(names(dataEX)[sapply(dataEX, is.character)])),
    #                      n=length(unique(diff(get(names(dataEX)[sapply(dataEX, lubridate::is.Date)])))))

    # print(Date_continuity)
    # print(dataEX)
    
    # if (any(Date_continuity$n > 1)) {
    #     stop (paste0("There is at least one date discontinuity in time serie(s) named '",
    #                  paste0(Date_continuity[[1]][Date_continuity$n > 1],
    #                         collapse=", "), "'. Please, make time serie(s) continuous by adding NA value in numerical column(s) where there is a missing value."))
    # }


    # check suffix
    if (!is.null(suffix)) {
        if (!is.character(suffix)) {
            stop ("'suffix' needs to be an object of class 'character'.")
        }
        if (!is.null(suffix_delimiter)) {
            if (is.character(suffix) & length(suffix_delimiter) == 1) {
                suffix = paste0(suffix_delimiter, suffix)
            } else {
                stop ("'suffix_delimiter' needs to be an object of class 'character' of length 1.")
            }
        } else {
            stop ("'suffix_delimiter' needs to be an object of class 'character' of length 1.")
        }
    }

    check_date = function (x) {try(as.Date(x), silent=TRUE)}
    check_order = function (x) {all(order(x) == c(2, 1))}
    
    # check period
    if (!is.null(period_trend)) {
        if (!is.list(period_trend)) {
            period_trend = list(period_trend)
        }
        nPeriod_trend = length(period_trend)
        test = unlist(lapply(period_trend, check_date))
        if (any("try-error" %in% class(test)) || any(is.na(test))) {
            stop ("'period_trend' is not in a format able to be coerced to a 'Date' object")
        }
        if (any(unlist(lapply(period_trend, length)) == 1)) {
            stop ("There is only one date in 'period_trend'. Please, select a time period in your time serie(s) with two objects of class 'Date' or set 'period_trend' to NULL in order to use the entire available time serie(s).")
        }
        if (any(unlist(lapply(period_trend, length)) > 2)) {
            stop ("There is more than two date in 'period_trend'. Please, select a time period in your time serie(s) with two objects of class 'Date' or set 'period_trend' to NULL in order to use the entire available time serie(s).")
        }
        if (any(unlist(lapply(period_trend, check_order)))) {
            message ("'period_trend' seems to have two date not in the increasing order. Thus, 'period_trend' will be re-ordered.")
            period_trend = lapply(period_trend, sort)
        }
    } else {
        nPeriod_trend = 1
    }

    

    if (!is.null(period_change)) {
        if (!is.list(period_change)) {
            period_change = list(period_change)
        }
        nPeriod_change = length(period_change)
        test = unlist(lapply(period_change, check_date))
        if (any("try-error" %in% class(test)) || any(is.na(test))) {
            stop ("'period_change' is not in a format able to be coerced to a 'Date' object")
        }
        if (any(unlist(lapply(period_trend, length)) == 1)) {
            stop ("There is only one date in 'period_change'. Please, select a time period in your time serie(s) with two objects of class 'Date' or set 'period_change' to NULL in order to use the entire available time serie(s).")
        }
        if (any(unlist(lapply(period_trend, length)) > 2)) {
            stop ("There is more than two date in 'period_change'. Please, select a time period in your time serie(s) with two objects of class 'Date' or set 'period_change' to NULL in order to use the entire available time serie(s).")
        }
        if (any(unlist(lapply(period_change, check_order)))) {
            message ("'period_change' seems to have two date not in the increasing order. Thus, 'period_change' will be re-ordered.")
            period_change = lapply(period_change, sort)
        }
        period_change = lapply(period_change, as.Date)
        
    } else {
        nPeriod_change = 1
    }

    # check verbose
    if (!is.logical(verbose)) {
        stop ("'verbose' needs to be an object of class 'logical'.")
    }
    
    tree("TREND ANALYSE", 0, verbose=verbose)

    names_save = names(dataEX)
    idCode_save = NULL
    idDate_save = NULL
    idVariable = c()
    names_save = names(dataEX)
    
    for (id in 1:ncol(dataEX)) {
        x = dataEX[[id]]

        if (is.character(x)) {
            idCode_save = id
        } else if (lubridate::is.Date(x)) {
            idDate_save = id
        } else if (is.numeric(x) | is.logical(x)) {
            idVariable = c(idVariable, id)
        }
    }
    
    # dataEX = dplyr::relocate(dataEX,
    #                          names_save[idDate_save],
    #                          .before=dplyr::everything())
    # dataEX = dplyr::relocate(dataEX,
    #                          names_save[idCode_save],
    #                          .before=dplyr::everything())

    # names_save = names(dataEX)
    # idVariable = c()
    # for (id in 1:ncol(dataEX)) {
    #     x = dataEX[[id]]

    #     if (is.character(x)) {
    #         idCode_save = id
    #     } else if (lubridate::is.Date(x)) {
    #         idDate_save = id
    #     } else if (is.numeric(x) | is.logical(x)) {
    #         idVariable_save = c(idVariable_save, id)
    #     }
    # }

    nVariable = length(idVariable)
    Variable = names(dataEX)[idVariable]
    # colName = paste0("Variable", 1:nVariable)
    
    # names(dataEX)[c(idCode_save, idDate_save, idVariable_save)] =
    # c("code", "date", unlist(colName))
    names(dataEX)[c(idCode_save, idDate_save)] =
        c("code", "date")
    
    
    trendEX = dplyr::tibble()
    
    for (j in 1:nPeriod_trend) {
        if (is.null(period_trend)) {
            dataEX_period = dataEX
        } else {
            period = as.Date(period_trend[[j]])
            if (is.na(period[1])) {
                period[1] = min(dataEX$date, na.rm=TRUE)
            }
            if (is.na(period[2])) {
                period[2] = max(dataEX$date, na.rm=TRUE)
            }
            
            dataEX_period = dplyr::filter(dataEX,
                                          min(period) <= date &
                                          date <= max(period))
        }

        tree(paste0("For period ", paste0(period, collapse=" ")),
             1, end=j==nPeriod_trend, verbose=verbose)
        if (j==nPeriod_trend) {
            inEnd_period = 1
        } else {
            inEnd_period = NULL
        }
        
        dataEX_period = dplyr::group_by(dataEX_period, code)
        trendEX_period = dplyr::tibble()
        
        for (k in 1:nVariable) {
            variable = Variable[k]

            tree(paste0("For variable ", variable),
                 2, end=k==nVariable&is.null(metaEX),
                 inEnd=inEnd_period, verbose=verbose)
            if (k == nVariable & is.null(metaEX)) {
                inEnd = c(inEnd_period, 2)
            } else {
                inEnd = inEnd_period
            }
            
            dataEX_period_Variable =
                dplyr::select(dataEX_period,
                              dplyr::all_of(c("code", "date",
                                              variable)))

            tree(paste0("Application of the Mann-Kendall statistical test ",
                        "with a level of ",
                        round(MK_level*100), " % and ",
                        time_dependency_option, " time dependency option"),
                 3, inEnd=inEnd, verbose=verbose)
            
            trendEX_period_Variable =
                dplyr::summarise(dataEX_period_Variable,
                                 GeneralMannKendall_WRAP(
                                     get(variable),
                                     level=MK_level,
                                     time_dependency_option=
                                         time_dependency_option,
                                     DoDetrending=TRUE,
                                     show_advance_stat=show_advance_stat,
                                     verbose=verbose_stat))

            trendEX_period_Variable$variable_en = variable
            trendEX_period_Variable = dplyr::relocate(trendEX_period_Variable,
                                                      variable_en,
                                                      .after=code)
            if (!is.null(suffix)) {
                variable_no_suffix = variable
                for (i in 1:length(suffix)) {
                    variable_no_suffix = gsub(suffix[i], "",
                                              variable_no_suffix,
                                              fixed=TRUE)
                }
                trendEX_period_Variable$variable_no_suffix_en = variable_no_suffix
                trendEX_period_Variable = dplyr::relocate(trendEX_period_Variable,
                                                          variable_no_suffix_en,
                                                          .after=variable_en)
            }
            
            tree(paste0("Estimation of other variable"),
                 3, end=TRUE, inEnd=inEnd, verbose=verbose)
            
            tree("Computing of the intercept of trend",
                 4, inEnd=c(inEnd, 3), verbose=verbose)
            trendEX_period_Variable = get_intercept(dataEX_period_Variable,
                                                    trendEX_period_Variable,
                                                    verbose=verbose)

            tree("Computing of the optimal period",
                 4, end=is.null(metaEX), inEnd=c(inEnd, 3), verbose=verbose)
            trendEX_period_Variable = get_period(dataEX_period_Variable,
                                                 trendEX_period_Variable,
                                                 verbose=verbose)
            
            if (!is.null(metaEX)) {
                tree("Normalise trend value",
                     4, end=is.null(period_change), inEnd=c(inEnd, 3), verbose=verbose)
                trendEX_period_Variable =
                    get_normalise(dataEX_period_Variable,
                                  trendEX_period_Variable,
                                  metaEX,
                                  suffix=suffix,
                                  verbose=verbose)
            }

            if (!is.null(period_change) & !is.null(metaEX)) {
                tree("Get period change",
                     4, end=TRUE, inEnd=c(inEnd, 3), verbose=verbose)
                trendEX_period_Variable =
                    get_change(dataEX_period_Variable, 
                               trendEX_period_Variable,
                               metaEX,
                               period_change,
                               suffix=suffix,
                               verbose=verbose)
            }
            
            trendEX_period = dplyr::bind_rows(trendEX_period,
                                              trendEX_period_Variable)
        }
        
        if (!is.null(metaEX)) {
            tree(paste0("Computing extreme trend values"),
                 2, end=is.null(period_change), inEnd=inEnd_period, verbose=verbose)
            trendEX_period =
                get_extreme_trend(trendEX_period,
                                  suffix=suffix,
                                  extreme_take_not_signif_into_account=
                                      extreme_take_not_signif_into_account,
                                  extreme_take_only_id=extreme_take_only_id,
                                  extreme_by_suffix=extreme_by_suffix, 
                                  extreme_prob=extreme_prob,
                                  verbose=verbose)
        }
        
        if (!is.null(period_change) & !is.null(metaEX)) {
            tree(paste0("Computing extreme change values"),
                 2, end=TRUE, inEnd=inEnd_period, verbose=verbose)
            trendEX_period =
                get_extreme_change(trendEX_period,
                                   suffix=suffix,
                                   extreme_take_only_id=extreme_take_only_id,
                                   extreme_by_suffix=extreme_by_suffix, 
                                   extreme_prob=extreme_prob,
                                   verbose=verbose)
        }

        trendEX = dplyr::bind_rows(trendEX, trendEX_period)
    }

    # if (isFDR) { ### /!\ pas ok
    #     dataEX.final$p.FDR =
    #         fieldSignificance_FDR(dataEX.final$p,
    #                               level=FDR_level)
    # }

    idCode = which(names(trendEX) == "code")

    names(trendEX)[c(idCode)] =
        names_save[c(idCode_save)]

    if (length(ID_colnames) > 1) {
        trendEX = tidyr::separate(trendEX, col="ID",
                                  into=ID_colnames, sep="_")
    }

    return (trendEX)
}



#### 2.3.2. Period of trend analysis _________________________________
#' @title get_period
#' @description Computes the optimal periods for trend analysis based on the data.
#'
#' @param dataEX A data frame containing the data.
#' @param trendEX A data frame containing the results of the trend analysis.
#' @param verbose A logical value indicating whether to display verbose output (default is TRUE).
#'
#' @return A modified data frame with an additional column indicating the optimal periods for trend analysis.
#'
#' @details The function computes the optimal periods for trend analysis based on the data. It calculates the minimum and maximum dates (start and end) for each code group in the data. Then, it creates a new column called "period" that contains a list of the start and end dates for each code group. The function then joins this information with the trend analysis results using the "code" column.
#'
#' @note documentation generated by chatGPT
#'
#' @importFrom dplyr group_by summarise full_join select
#'
#' @export
get_period = function (dataEX, trendEX, verbose=TRUE) {

    Period = dplyr::summarise(dplyr::group_by(dataEX, code),
                              start=min(date, na.rm=TRUE),
                              end=max(date, na.rm=TRUE),
                              period_trend=list(c(start, end)))
    
    trendEX = dplyr::full_join(trendEX,
                               dplyr::select(Period,
                                             c("code",
                                               "period_trend")),
                               by="code")
    return (trendEX)
}

#### 2.3.3. Intercept of trend _______________________________________
#' @title get_intercept
#' @description Computes the intercept of the trend in the data.
#'
#' @param dataEX A data frame containing the data.
#' @param trendEX A data frame containing the results of the trend analysis.
#' @param verbose A logical value indicating whether to display verbose output (default is TRUE).
#'
#' @return A modified data frame with an additional column indicating the intercept of the trend.
#'
#' @details The function computes the intercept of the trend in the data based on the results of the trend analysis. It calculates the mean value of the dependent variable (Variable) and the mean time variable (date) for each code group. Then, it computes the intercept using the formula: b = mu_X - mu_t * a, where mu_X is the mean value, mu_t is the mean time, and a is the slope of the trend.
#'
#' @note documentation generated by chatGPT
#'
#' @importFrom dplyr group_by summarise full_join
#'
#' @export
get_intercept = function (dataEX, trendEX,
                          verbose=TRUE) {

    variable =  levels(factor(trendEX$variable_en))
    
    MU_X = dplyr::summarise(dplyr::group_by(dataEX, code),
                            mu_X=mean(get(variable),
                                      na.rm=TRUE))

    MU_t = dplyr::summarise(dplyr::group_by(dataEX, code),
                            mu_t=as.numeric(mean(date,
                                                 na.rm=TRUE)) /
                                mean(as.numeric(diff(date)), na.rm=TRUE))

    analyse = dplyr::tibble(code=trendEX$code,
                            a=trendEX$a,
                            mu_X=MU_X$mu_X,
                            mu_t=MU_t$mu_t)
    
    B = dplyr::summarise(dplyr::group_by(analyse, code),
                         b=mu_X - mu_t * a)
    
    trendEX = dplyr::full_join(trendEX, B, by="code")

    trendEX$b[!is.finite(trendEX$b)] = NA

    return (trendEX)
}


get_normalise = function (dataEX, trendEX, metaEX,
                          suffix=NULL,
                          verbose=FALSE) {
    
    variable =  levels(factor(trendEX$variable_en))

    if (!is.null(suffix)) {
        variable_no_suffix = variable
        for (i in 1:length(suffix)) {
            variable_no_suffix = gsub(suffix[i], "",
                                      variable_no_suffix,
                                      fixed=TRUE)
        }
        to_normalise = metaEX$to_normalise[metaEX$variable_en == variable_no_suffix]
    } else {
        to_normalise = metaEX$to_normalise[metaEX$variable_en == variable]
    }

    if (to_normalise) {
        dataEX_mean =
            dplyr::summarise(group_by(dataEX, code),
                             mean=mean(get(variable),
                                       na.rm=TRUE))
        trendEX = full_join(trendEX,
                            dataEX_mean,
                            by="code")
        trendEX$a_normalise = trendEX$a / trendEX$mean * 100
        trendEX$mean[!is.finite(trendEX$mean)] = NA
        trendEX = dplyr::rename(trendEX, mean_period_trend=mean)
        
    } else {
        trendEX$mean_period_trend = NA
        trendEX$a_normalise = trendEX$a
    }
    return (trendEX)
}


get_change = function (dataEX, trendEX, metaEX,
                       period_change,
                       suffix=NULL,
                       verbose=FALSE) {
    
    variable =  levels(factor(trendEX$variable_en))

    if (!is.null(suffix)) {
        variable_no_suffix = variable
        for (i in 1:length(suffix)) {
            variable_no_suffix = gsub(suffix[i], "",
                                      variable_no_suffix,
                                      fixed=TRUE)
        }
        to_normalise = metaEX$to_normalise[metaEX$variable_en == variable_no_suffix]
    } else {
        to_normalise = metaEX$to_normalise[metaEX$variable_en == variable]
    }
    
    nPeriod_change = length(period_change)
    if (nPeriod_change != 2) {
        break
    }

    dataEX_change = 
        dplyr::summarise(dplyr::group_by(dataEX, code),
                         
                         start_1=max(c(period_change[[1]][1],
                                       min(date, na.rm=TRUE)), na.rm=TRUE),
                         end_1=min(c(period_change[[1]][2],
                                     max(date, na.rm=TRUE)), na.rm=TRUE),
                         
                         start_2=max(c(period_change[[2]][1],
                                       min(date, na.rm=TRUE)), na.rm=TRUE),
                         end_2=min(c(period_change[[2]][2],
                                     max(date, na.rm=TRUE)), na.rm=TRUE),
                         
                         .groups="drop")

    dataEX_change = 
        dplyr::mutate(dplyr::group_by(dataEX_change, code),
                      period_change=list(list(c(start_1, end_1),
                                              c(start_2, end_2))))
    
    dataEX_change_1 =
        dplyr::summarise(
                   dplyr::group_by(
                              dplyr::filter(dataEX,
                                            period_change[[1]][1] <= date &
                                            date <= period_change[[1]][2]),
                              code),
                   mean_1=mean(get(variable), na.rm=TRUE))

    dataEX_change_2 =
        dplyr::summarise(
                   dplyr::group_by(
                              dplyr::filter(dataEX,
                                            period_change[[2]][1] <= date &
                                            date <= period_change[[2]][2]),
                              code),
                   mean_2=mean(get(variable), na.rm=TRUE))

    dataEX_change_tmp = dplyr::full_join(dataEX_change_1, dataEX_change_2,
                                         by="code")
    dataEX_change_tmp =
        dplyr::mutate(dplyr::group_by(dataEX_change_tmp, code),
                      mean_period_change=list(c(mean_1, mean_2)))
    
    dataEX_change = dplyr::full_join(dataEX_change, dataEX_change_tmp,
                                     by="code")
    
    if (to_normalise) {
        dataEX_change$change =
            (dataEX_change$mean_2 - dataEX_change$mean_1) / dataEX_change$mean_1 * 100
    } else {
        dataEX_change$change =
            dataEX_change$mean_2 - dataEX_change$mean_1
    }

    dataEX_change$change[!is.finite(dataEX_change$change)] = NA
    
    trendEX = full_join(trendEX,
                        select(dataEX_change,
                               c("code",
                                 "period_change",
                                 "mean_period_change",
                                 "change")),
                        by="code")

    return (trendEX)
}



get_extreme_trend = function (trendEX,
                              suffix=NULL,
                              extreme_take_not_signif_into_account=TRUE,
                              extreme_take_only_id=NULL,
                              extreme_by_suffix=TRUE,
                              extreme_prob=0.01,
                              verbose=FALSE) {

    if (!extreme_take_not_signif_into_account) {
        trendEX_a_normalise = trendEX$a_normalise
        trendEX$a_normalise[!trendEX$H] = NA
    }

    if (is.null(extreme_take_only_id)) {
        extreme_take_only_id = trendEX$code
    }

    if (extreme_by_suffix) {
        variable_tmp = "variable_en" 
    } else {
        variable_tmp = "variable_no_suffix_en" 
    }
    
    trendEX = dplyr::mutate(dplyr::group_by(trendEX,
                                            !!!rlang::data_syms(variable_tmp)),
                            a_normalise_min=
                                quantile(a_normalise[code %in% extreme_take_only_id],
                                         extreme_prob,
                                         na.rm=TRUE),
                            a_normalise_max=
                                quantile(a_normalise[code %in% extreme_take_only_id],
                                         1-extreme_prob,
                                         na.rm=TRUE),
                            .keep="all")

    if (!extreme_take_not_signif_into_account) {
        trendEX$a_normalise = trendEX_a_normalise
    }
    
    return (trendEX)
}




get_extreme_change = function (trendEX,
                               suffix=NULL,
                               extreme_take_only_id=NULL,
                               extreme_by_suffix=TRUE,
                               extreme_prob=0.01,
                               verbose=FALSE) {

    if (is.null(extreme_take_only_id)) {
        extreme_take_only_id = trendEX$code
    }

    if (extreme_by_suffix) {
        variable_tmp = "variable_en" 
    } else {
        variable_tmp = "variable_no_suffix_en" 
    }
    
    trendEX = dplyr::mutate(dplyr::group_by(trendEX,
                                            !!!rlang::data_syms(variable_tmp)),
                            change_min=
                                quantile(change[code %in% extreme_take_only_id],
                                         extreme_prob,
                                         na.rm=TRUE),
                            change_max=
                                quantile(change[code %in% extreme_take_only_id],
                                         1-extreme_prob,
                                         na.rm=TRUE),
                            .keep="all")
    
    return (trendEX)
}

