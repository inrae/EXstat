# Copyright 2021-2023 Louis Héraut (louis.heraut@inrae.fr)*1,
#                     Éric Sauquet (eric.sauquet@inrae.fr)*1
#
# *1   INRAE, France
#
# This file is part of EXstat R package.
#
# EXstat R package is free software: you can redistribute it and/or
# modify it under the terms of the GNU General Public License as
# published by the Free Software Foundation, either version 3 of the
# License, or (at your option) any later version.
#
# EXstat R package is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with EXstat R package.
# If not, see <https://www.gnu.org/licenses/>.


#' @title process_trend
#' @description Analyzes the trend in data using statistical tests and estimation methods.
#'
#' @param dataEX A data frame containing the data to be analyzed.
#' @param metaEX A data frame containing metadata information (optional).
#' @param MK_level The significance level for the Mann-Kendall statistical test.
#' @param timeDep_option The time dependency option to use in the Mann-Kendall test.
#' @param take_not_signif_into_account Flag indicating whether to take into account non-significant trends.
#' @param period_trend A list of periods to consider for trend analysis (optional).
#' @param period_change A list of periods to consider for change analysis (optional).
#' @param exProb The extreme probability threshold for identifying extreme values (optional).
#' @param verbose Flag indicating whether to display verbose output during the analysis.
#' @param ... Additional parameters to be passed to the statistical test and estimation methods.
#'
#' @return A data frame containing the results of the trend analysis.
#'
#' @details The function analyzes the trend in the provided data using statistical tests, such as the Mann-Kendall test, and estimation methods. It computes the trend for each specified period, detects significant trends, estimates other variables related to the trend, and identifies extreme values if metadata information is provided.
#' 
#' @note documentation generated by chatGPT
#' 
#' @examples
#' # Date
#' Start = as.Date("1972-01-01")
#' End = as.Date("2020-12-31")
#' Date = seq.Date(Start, End, by="day")
#' 
#' # Value to analyse
#' set.seed(100)
#' X = seq(1, length(Date))/1e4 + runif(length(Date), -100, 100)
#' X[as.Date("2000-03-01") <= Date & Date <= as.Date("2000-09-30")] = NA
#'
#' # Creation of tibble
#' data = dplyr::tibble(date=Date, ID="serie A", X=X)
#'
#' # Extraction
#' dataEX = process_extraction(data=data,
#'                             sampling_period=c("05-01",
#'                                            "11-30"),
#'                             funct=max,
#'                             na.rm=TRUE,
#'                             period=c(as.Date("1990-01-01"),
#'                                      as.Date("2020-12-31")),
#'                             time_step="year")
#'
#' trendEX = process_trend(data=dataEX)
#' trendEX
#' 
#' @importFrom lubridate is.Date
#' @importFrom dplyr tibble group_by filter summarise bind_rows bind_cols
#'
#' @export
process_trend = function (dataEX,
                          metaEX=NULL,
                          MK_level=0.1,
                          timeDep_option="INDE",
                          # isFDR=FALSE,
                          # FDR_level=0.1,
                          suffix=NULL,
                          suffix_delimiter="_",
                          take_not_signif_into_account=TRUE,
                          period_trend=NULL,
                          period_change=NULL,
                          exProb=0.01,
                          dev=FALSE,
                          verbose=FALSE,
                          ...) {

    # check dataEX
    if (!tibble::is_tibble(dataEX)) {
        stop ("'dataEX' is not a tibble from the tibble package. This tibble needs a unique column of objects of class 'Date'")
    }
    
    # check Date column
    if (sum(sapply(dataEX, lubridate::is.Date)) == 0 & !dev) {
        stop ("There needs to be at least one column of objects of class 'Date'.")
    }
    if (sum(sapply(dataEX, lubridate::is.Date)) > 1) {
        stop ("There is more than one column of objects of class 'Date'. There needs to be only one column of objects of class 'Date'.")
    }

    # check numerical columns
    if (sum(sapply(dataEX, is.numeric) |
            sapply(dataEX, is.logical)) < 1) {
        stop ("There needs to be at least one column of class 'numeric' or 'logical'.")
    }
    
    # check character columns
    ID_colnames = names(dplyr::select(dataEX,
                                      dplyr::where(is.character)))
    if (sum(sapply(dataEX, is.character)) == 0 & !dev) {
        if (any(duplicated(
            dataEX[[which(sapply(dataEX,
                               lubridate::is.Date))]]))) {
            stop ("There is at least one date value that repeat. It seems that either there is more than one time serie (so they need to be identify by a repeted character column for each serie) or there is an error in the format of the date column.")
        } else {
            warning ("There is no character column in order to identify uniquely each time serie. But hence it seems that there is only one time serie, a generic identifier will be add.")
            dataEX$id = "time serie"
        }
    } else if (sum(sapply(dataEX, is.character)) > 1) {
        message ("There is more than one character column. Thus, all the columns will be use to identify uniquely each time serie.")
        dataEX = tidyr::unite(dataEX, "ID",
                            dplyr::where(is.character),
                            sep="_")
    }

    # DATE NA

    if (!dev) {
        # check unicity of Date column for each character identifier
        Date_unicity =
            dplyr::summarise(dplyr::group_by(dataEX,
                                             get(names(dataEX)[sapply(dataEX, is.character)])),
                             n=sum(duplicated(get(names(dataEX)[sapply(dataEX, lubridate::is.Date)]))))
        if (any(Date_unicity$n > 0)) {
            stop (paste0("There is at least one duplicated date in time serie(s) named '",
                         paste0(Date_unicity[[1]][Date_unicity$n > 0],
                                collapse=", "), "'."))
        }
    }
    
    # # check continuity of Date column for each character identifier
    # Date_continuity =
    #     dplyr::summarise(dplyr::group_by(dplyr::arrange(dataEX, get(names(dataEX)[sapply(dataEX, lubridate::is.Date)])),
    #                                      get(names(dataEX)[sapply(dataEX, is.character)])),
    #                      n=length(unique(diff(get(names(dataEX)[sapply(dataEX, lubridate::is.Date)])))))

    # print(Date_continuity)
    # print(dataEX)
    
    # if (any(Date_continuity$n > 1)) {
    #     stop (paste0("There is at least one date discontinuity in time serie(s) named '",
    #                  paste0(Date_continuity[[1]][Date_continuity$n > 1],
    #                         collapse=", "), "'. Please, make time serie(s) continuous by adding NA value in numerical column(s) where there is a missing value."))
    # }





    # check suffix
    if (!is.null(suffix)) {
        if (!is.character(suffix)) {
            stop ("'suffix' needs to be an object of class 'character'.")
        }
        if (!is.null(suffix_delimiter)) {
            if (is.character(suffix) & length(suffix_delimiter) == 1) {
                suffix = paste0(suffix_delimiter, suffix)
            } else {
                stop ("'suffix_delimiter' needs to be an object of class 'character' of length 1.")
            }
        } else {
            stop ("'suffix_delimiter' needs to be an object of class 'character' of length 1.")
        }
    }

    check_date = function (x) {try(as.Date(x), silent=TRUE)}
    check_order = function (x) {all(order(x) == c(2, 1))}
    
    # check period
    if (!is.null(period_trend)) {
        if (!is.list(period_trend)) {
            period_trend = list(period_trend)
        }
        nPeriod_trend = length(period_trend)
        test = unlist(lapply(period_trend, check_date))
        if (any("try-error" %in% class(test)) || any(is.na(test))) {
            stop ("'period_trend' is not in a format able to be coerced to a 'Date' object")
        }
        if (any(unlist(lapply(period_trend, length)) == 1)) {
            stop ("There is only one date in 'period_trend'. Please, select a time period in your time serie(s) with two objects of class 'Date' or set 'period_trend' to NULL in order to use the entire available time serie(s).")
        }
        if (any(unlist(lapply(period_trend, length)) > 2)) {
            stop ("There is more than two date in 'period_trend'. Please, select a time period in your time serie(s) with two objects of class 'Date' or set 'period_trend' to NULL in order to use the entire available time serie(s).")
        }
        if (any(unlist(lapply(period_trend, check_order)))) {
            message ("'period_trend' seems to have two date not in the increasing order. Thus, 'period_trend' will be re-ordered.")
            period_trend = lapply(period_trend, sort)
        }
    } else {
        nPeriod_trend = 1
    }

    

    if (!is.null(period_change)) {
        if (!is.list(period_change)) {
            period_change = list(period_change)
        }
        nPeriod_change = length(period_change)
        test = unlist(lapply(period_change, check_date))
        if (any("try-error" %in% class(test)) || any(is.na(test))) {
            stop ("'period_change' is not in a format able to be coerced to a 'Date' object")
        }
        if (any(unlist(lapply(period_trend, length)) == 1)) {
            stop ("There is only one date in 'period_change'. Please, select a time period in your time serie(s) with two objects of class 'Date' or set 'period_change' to NULL in order to use the entire available time serie(s).")
        }
        if (any(unlist(lapply(period_trend, length)) > 2)) {
            stop ("There is more than two date in 'period_change'. Please, select a time period in your time serie(s) with two objects of class 'Date' or set 'period_change' to NULL in order to use the entire available time serie(s).")
        }
        if (any(unlist(lapply(period_change, check_order)))) {
            message ("'period_change' seems to have two date not in the increasing order. Thus, 'period_change' will be re-ordered.")
            period_change = lapply(period_change, sort)
        }
    } else {
        nPeriod_change = 1
    }

    # check verbose
    if (!is.logical(verbose)) {
        stop ("'verbose' needs to be an object of class 'logical'.")
    }
 
    tree("TREND ANALYSE", 0, verbose=verbose)

    names_save = names(dataEX)
    idCode_save = NULL
    idDate_save = NULL
    idValue_save = c()
    
    for (id in 1:ncol(dataEX)) {
        x = dataEX[[id]]

        if (is.character(x)) {
            idCode_save = id
        } else if (lubridate::is.Date(x)) {
            idDate_save = id
        } else if (is.numeric(x) | is.logical(x)) {
            idValue_save = c(idValue_save, id)
        }
    }
    
    dataEX = dplyr::relocate(dataEX,
                             names_save[idDate_save],
                             .before=dplyr::everything())
    dataEX = dplyr::relocate(dataEX,
                             names_save[idCode_save],
                             .before=dplyr::everything())

    names_save = names(dataEX)
    idValue_save = c()
    for (id in 1:ncol(dataEX)) {
        x = dataEX[[id]]

        if (is.character(x)) {
            idCode_save = id
        } else if (lubridate::is.Date(x)) {
            idDate_save = id
        } else if (is.numeric(x) | is.logical(x)) {
            idValue_save = c(idValue_save, id)
        }
    }

    nValue = length(idValue_save)
    colName = paste0("Value", 1:nValue)

    names(dataEX)[c(idCode_save, idDate_save, idValue_save)] =
        c("code", "date", unlist(colName))

    

    trendEX = dplyr::tibble()
    
    for (j in 1:nPeriod_trend) {

        if (is.null(period_trend)) {
            dataEX_period = dataEX
        } else {
            period = as.Date(period_trend[[j]])
            if (is.na(period[1])) {
                period[1] = min(dataEX$date, na.rm=TRUE)
            }
            if (is.na(period[2])) {
                period[2] = max(dataEX$date, na.rm=TRUE)
            }
            
            dataEX_period = dplyr::filter(dataEX,
                                          min(period) <= date &
                                          date <= max(period))
        }
        
        tree("Grouping dataEX by code", 1, verbose=verbose)
        # Group dataEX accordingly to group.names
        dataEX_period = dplyr::group_by(dataEX_period, code)

        tree("Statistical test",
             1, verbose=verbose)

        tree(paste0("Application of the Mann-Kendall statistical test ",
                    "with a level of ",
                    round(MK_level*100), " % and ",
                    timeDep_option, " time dependency option"),
             2, verbose=verbose)

        
        for (k in 1:nValue) {
            dataEX_period_Value =
                dplyr::select(dataEX_period,
                              dplyr::all_of(c("code", "date",
                                              paste0("Value", k))))
            trendEX_period_Value =
                dplyr::summarise(dataEX_period_Value,
                                 GeneralMannKendall_WRAP(
                                     get(paste0("Value", k)),
                                     level=MK_level,
                                     timeDep_option=timeDep_option,
                                     ...))
            
            tree("Estimation of other variable",
                 1, end=TRUE, verbose=verbose)
            trendEX_period_Value = get_intercept(dataEX_period_Value,
                                                 trendEX_period_Value,
                                                 verbose=verbose)
            trendEX_period_Value = get_period(dataEX_period_Value,
                                              trendEX_period_Value,
                                              verbose=verbose)

            trendEX_period_Value =
                dplyr::bind_cols(trendEX_period_Value,
                                 variable_en=names_save[idValue_save[k]])

            if (!is.null(metaEX)) {
                dataEX_Value =
                    dplyr::select(dataEX,
                                  dplyr::all_of(c("code", "date",
                                                  paste0("Value", k))))
                trendEX_period_Value =
                    get_valueExtremes(dataEX_Value, metaEX,
                                      trendEX_period_Value,
                                      suffix=suffix,
                                      take_not_signif_into_account=
                                          take_not_signif_into_account,
                                      period_change=period_change,
                                      exProb=exProb,
                                      verbose=verbose)
            }
            
            if (nrow(trendEX) == 0) {
                trendEX = trendEX_period_Value
            } else {
                trendEX = dplyr::bind_rows(trendEX,
                                           trendEX_period_Value)
            }
        }
    }




    # if (isFDR) { ### /!\ pas ok
    #     dataEX.final$p.FDR =
    #         fieldSignificance_FDR(dataEX.final$p,
    #                               level=FDR_level)
    # }

    idCode = which(names(trendEX) == "code")

    names(trendEX)[c(idCode)] =
        names_save[c(idCode_save)]


    if (length(ID_colnames) > 1) {
        trendEX = tidyr::separate(trendEX, col="ID",
                                  into=ID_colnames, sep="_")
    }

    return (trendEX)
}



#### 2.3.2. Period of trend analysis _________________________________
#' @title get_period
#' @description Computes the optimal periods for trend analysis based on the data.
#'
#' @param dataEX A data frame containing the data.
#' @param trendEX A data frame containing the results of the trend analysis.
#' @param verbose A logical value indicating whether to display verbose output (default is TRUE).
#'
#' @return A modified data frame with an additional column indicating the optimal periods for trend analysis.
#'
#' @details The function computes the optimal periods for trend analysis based on the data. It calculates the minimum and maximum dates (start and end) for each code group in the data. Then, it creates a new column called "period" that contains a list of the start and end dates for each code group. The function then joins this information with the trend analysis results using the "code" column.
#'
#' @note documentation generated by chatGPT
#'
#' @importFrom dplyr group_by summarise full_join select
#'
#' @export
get_period = function (dataEX, trendEX, verbose=TRUE) {

    tree("Computing of the optimal periods of trend analysis",
         2, end=TRUE, inEnd=1, verbose=verbose)

    Period = dplyr::summarise(dplyr::group_by(dataEX, code),
                              start=min(date, na.rm=TRUE),
                              end=max(date, na.rm=TRUE),
                              period=list(c(start, end)))
    
    trendEX = dplyr::full_join(trendEX,
                               dplyr::select(Period,
                                             c("code",
                                               "period")),
                               by="code")
    return (trendEX)
}

#### 2.3.3. Intercept of trend _______________________________________
#' @title get_intercept
#' @description Computes the intercept of the trend in the data.
#'
#' @param dataEX A data frame containing the data.
#' @param trendEX A data frame containing the results of the trend analysis.
#' @param verbose A logical value indicating whether to display verbose output (default is TRUE).
#'
#' @return A modified data frame with an additional column indicating the intercept of the trend.
#'
#' @details The function computes the intercept of the trend in the data based on the results of the trend analysis. It calculates the mean value of the dependent variable (Value) and the mean time variable (date) for each code group. Then, it computes the intercept using the formula: b = mu_X - mu_t * a, where mu_X is the mean value, mu_t is the mean time, and a is the slope of the trend.
#'
#' @note documentation generated by chatGPT
#'
#' @importFrom dplyr group_by summarise full_join
#'
#' @export
get_intercept = function (dataEX, trendEX,
                          verbose=TRUE) {

    tree("Computing of the intercept of trend",
         2, inEnd=1, verbose=verbose)

    Value = grep("Value", names(dataEX), value=TRUE)
    
    MU_X = dplyr::summarise(dplyr::group_by(dataEX, code),
                            mu_X=mean(get(Value),
                                      na.rm=TRUE))

    MU_t = dplyr::summarise(dplyr::group_by(dataEX, code),
                            mu_t=as.numeric(mean(date,
                                                 na.rm=TRUE)) /
                            mean(as.numeric(diff(date)), na.rm=TRUE))

    analyse = dplyr::tibble(code=trendEX$code,
                            a=trendEX$a,
                            mu_X=MU_X$mu_X,
                            mu_t=MU_t$mu_t)
    
    B = dplyr::summarise(dplyr::group_by(analyse, code),
                         b=mu_X - mu_t * a)
    
    trendEX = dplyr::full_join(trendEX, B, by="code")

    return (trendEX)
}


#' @title get_valueExtremes
#' @description Identifies extreme values in the data based on trend analysis.
#'
#' @param dataEX A data frame containing the data.
#' @param metaEX A data frame containing metadata information.
#' @param trendEX A data frame containing the results of the trend analysis.
#' @param take_not_signif_into_account Flag indicating whether to take into account non-significant trends.
#' @param period_change A list of periods to consider for change analysis (optional).
#' @param exProb The extreme probability threshold for identifying extreme values.
#'
#' @return A modified data frame with additional columns indicating extreme values.
#'
#' @details The function identifies extreme values in the data based on the results of the trend analysis. It computes the trend and change for each period and code, and determines extreme values based on the specified extreme probability threshold. If period change analysis is enabled, it also calculates the change between specified periods.
#'
#' @note documentation generated by chatGPT
#'
#' @importFrom dplyr group_by filter select mutate ungroup
#'
#' @export
get_valueExtremes = function (dataEX, metaEX, trendEX,
                              suffix=NULL,
                              take_not_signif_into_account=TRUE,
                              period_change=NULL,
                              exProb=0.01,
                              verbose=FALSE) {

    tree("Computing extrem values",
         2, end=TRUE, inEnd=1, verbose=verbose)

    Value = grep("Value", names(dataEX), value=TRUE)
    
    Code = levels(factor(dataEX$code))
    nCode = length(Code)
    # period = unique(trendEX$period)
    variable =  levels(factor(trendEX$variable_en))

    dataEX = dplyr::full_join(dataEX,
                              dplyr::select(trendEX,
                                            "code",
                                            "period"),
                              by="code")

    if (!is.null(suffix)) {
        variable_no_suffix = variable
        for (i in 1:length(suffix)) {
            variable_no_suffix = gsub(suffix[i], "",
                                 variable_no_suffix,
                                 fixed=TRUE)
        }
        to_normalise = metaEX$to_normalise[metaEX$variable_en == variable_no_suffix]
    } else {
        to_normalise = metaEX$to_normalise[metaEX$variable_en == variable]
    }

    if (to_normalise) {
        dataEX = dplyr::filter(dataEX,
                               date >= period[[1]][1] &
                               date <= period[[1]][2],
                               .by="code")
        
        dataEX_mean =
            dplyr::summarise(group_by(dataEX, code),
                             mean=mean(get(Value),
                                       na.rm=TRUE))

        trendEX = full_join(trendEX,
                            dataEX_mean,
                            by="code")
        
        trendEX$a_normalise = trendEX$a / trendEX$mean * 100
        
    } else {
        trendEX$mean = NA
        trendEX$a_normalise = trendEX$a
    }
        
    if (!is.null(period_change)) {
        nPeriod_change = length(period_change)
        if (nPeriod_change != 2) {
            break
        }

        for (jj in 1:nPeriod_change) {
            dataEX = dataEX[dataEX$date >=
                            period_change[[jj]][1] &
                            dataEX$date <=
                            period_change[[jj]][2],]

            dataMean =
                dplyr::summarise(group_by(dataEX, code),
                                 mean=mean(get(Value), na.rm=TRUE))
            
            if (jj == 1) {
                dataMean_tmp = dataMean                            
            } else {
                if (to_normalise) {
                    dataMean$change =
                        (dataMean$mean - dataMean_tmp$mean) /
                        dataMean_tmp$mean
                } else {
                    dataMean$change = dataMean$mean - dataMean_tmp$mean
                }
            }
        }

        dataMean$period_change = list(period_change)
        trendEX = full_join(trendEX,
                            select(dataMean,
                                   c("code",
                                     "period_change",
                                     "change")),
                            by="code")
    }
    
    if (!is.null(period_change)) {
        trendEX = dplyr::mutate(trendEX,
                                change_min=quantile(change,
                                                    exProb,
                                                    na.rm=TRUE),
                                change_max=quantile(change,
                                                    1-exProb,
                                                    na.rm=TRUE),
                                .keep="all")
    }

    if (!take_not_signif_into_account) {
        trendEX_a_normalise = trendEX$a_normalise
        trendEX$a_normalise[!trendEX$H] = NA
    }
    
    trendEX = dplyr::mutate(trendEX,
                            a_normalise_min=quantile(a_normalise,
                                                     exProb,
                                                     na.rm=TRUE),
                            a_normalise_max=quantile(a_normalise,
                                                     1-exProb,
                                                     na.rm=TRUE),
                            .keep="all")

    if (!take_not_signif_into_account) {
        trendEX$a_normalise = trendEX_a_normalise
    }

    return (trendEX)
}
