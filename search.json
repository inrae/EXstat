[{"path":"/CODE_OF_CONDUCT.html","id":null,"dir":"","previous_headings":"","what":"Contributor Code of Conduct","title":"Contributor Code of Conduct","text":"contributors maintainers project, pledge respect people contribute reporting issues, posting feature requests, updating documentation, submitting pull requests patches, activities. committed making participation project harassment-free experience everyone, regardless level experience, gender, gender identity expression, sexual orientation, disability, personal appearance, body size, race, ethnicity, age, religion. Examples unacceptable behavior participants include use sexual language imagery, derogatory comments personal attacks, trolling, public private harassment, insults, unprofessional conduct. Project maintainers right responsibility remove, edit, reject comments, commits, code, wiki edits, issues, contributions aligned Code Conduct. Project maintainers follow Code Conduct may removed project team. Instances abusive, harassing, otherwise unacceptable behavior may reported opening issue contacting one project maintainers. Code Conduct adapted Contributor Covenant (https://www.contributor-covenant.org), version 1.0.0, available https://contributor-covenant.org/version/1/0/0/.","code":""},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Benjamin Renard. Author. Valentin Mansanarez. Author. Louis Héraut. Maintainer, author. Éric Sauquet. Contributor. Jean-Philippe Vidal. Contributor. Nathan Pellerin. Contributor.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Renard B, Mansanarez V, Héraut L (2025). EXstat: EXstat. R package version 2.4.0.9000.","code":"@Manual{,   title = {EXstat: EXstat},   author = {Benjamin Renard and Valentin Mansanarez and Louis Héraut},   year = {2025},   note = {R package version 2.4.0.9000}, }"},{"path":"/index.html","id":"exstat-","dir":"","previous_headings":"","what":"EXstat","title":"EXstat","text":"EXstat R package provide efficient simple solution aggregate analyze stationarity time series. project carried National Research Institute Agriculture, Food Environment (Institut National de Recherche pour l’Agriculture, l’Alimentation et l’Environnement, INRAE french).","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"EXstat","text":"latest development version","code":"remotes::install_github(\"super-lou/EXstat\")"},{"path":[]},{"path":"/index.html","id":"extraction-process","dir":"","previous_headings":"Documentation","what":"Extraction process","title":"EXstat","text":"Based dplyr, input data format tibble least column date, columns numeric value one character columns names time series order identify uniquely. Thus possible tibble multiple time series can grouped names. example, can use following tibble : looks like : process variable extraction (example yearly mean time series) realised process_extraction() function. Minimum arguments : * Input data described * function funct (example mean) want use. Arguments chosen function can passed extraction process function can previously defined. optional arguments : * period vector two dates (two unambiguous character strings can coerced dates) restrict period analysis. example, can c(\"1950-01-01\", \"2020-12-31\") select data 1st January 1950 end December 2020. default option period=NULL, considers available data time serie. * time_step character string specifying time step variable extraction process. Possible values : - “year” value per year - “month” value month year (12 values least full year given) - “year-month” value month year (12 times number given year values end) - “season” value season th year (default 4 values) - “year-season” value season year (default 4 times number given year values end) - “yearday” one value per day year (365 values end least full year given… one year seems obviously interesting) - “none” want extract unique value whole time serie * sampling_period character string vector two character strings indicate sample data time step defined time_step. Hence, choice argument needs link choice time step. example, yearly extraction time_step set \"year\", sampling_period needs formated %m-%d (month - day year) order indicate start sampling data current year. precisly, time_step=\"year\" sampling_period=\"03-19\", funct apply every data 3rd march year 2nd march following one. way, possible create sub-year sampling vector two character strings sampling_period=c(\"02-01\", \"07-31\") order process data date 1st february 31th jully year. parameters available, example, : * handle missing values, * use suffixes simplify expressions, * manage variables related seasonality. way perform yearly extraction maximum value may november, 1th march 1990 31th october 2020, ignoring NA values. output also tibble column date, character name time series numerical column extracted variable time series. examples complex cases available package documentation. Try starting ","code":"library(dplyr)  # Date Start = as.Date(\"1972-01-01\") End = as.Date(\"2020-12-31\") Date = seq.Date(Start, End, by=\"day\")  # Value to analyse set.seed(100) X = seq(1, length(Date))/1e4 + runif(length(Date), -100, 100) X[as.Date(\"2000-03-01\") <= Date & Date <= as.Date(\"2000-09-30\")] = NA  # Creation of tibble data = tibble(Date=Date, ID=\"serie A\", X=X) > data # A tibble: 17,898 × 3    Date       ID           X    <date>     <chr>    <dbl>  1 1972-01-01 serie A -38.4   2 1972-01-02 serie A -48.5   3 1972-01-03 serie A  10.5   4 1972-01-04 serie A -88.7   5 1972-01-05 serie A  -6.29  6 1972-01-06 serie A  -3.25  7 1972-01-07 serie A  62.5   8 1972-01-08 serie A -25.9   9 1972-01-09 serie A   9.31 10 1972-01-10 serie A -65.9  # ℹ 17,888 more rows # ℹ Use `print(n = ...)` to see more rows dataEX = process_extraction(data=data,                             funct=max,                             funct_args=list(\"X\", na.rm=TRUE),                             time_step=\"year\",                             sampling_period=c(\"05-01\",                                               \"11-30\"),                             period=c(as.Date(\"1990-01-01\"),                                      as.Date(\"2020-12-31\"))) > dataEX # A tibble: 31 × 3    ID      Date           X    <chr>   <date>     <dbl>  1 serie A 1990-05-01 100.   2 serie A 1991-05-01 101.   3 serie A 1992-05-01 100.   4 serie A 1993-05-01  99.9  5 serie A 1994-05-01  99.0  6 serie A 1995-05-01 100.   7 serie A 1996-05-01 100.   8 serie A 1997-05-01 101.   9 serie A 1998-05-01  99.6 10 serie A 1999-05-01 101.  # ℹ 21 more rows # ℹ Use `print(n = ...)` to see more rows library(EXstat) ?EXstat"},{"path":"/index.html","id":"extraction-process-with-card","dir":"","previous_headings":"Documentation","what":"Extraction process with CARD","title":"EXstat","text":"user-friendly interaction, package developed symbiosis predefined parameterisation files called CARD. don’t define complex parameters extract hydroclimatological variables. ’s , CARD want doesn’t exist, ’s easy create one based others. , need download CARD archive, extract place wherever like (data). can create new subdirectory within main CARD directory, can call example \"analyse_1\", copy paste CARD \"__all__/Hautes_Eaux/QJXA.R\" . way, can carry “analyse_1” running: Thus, can place several CARDs \"analyse_1\" sub-directory multiple analyses. However, copy/pasting action can quite cumbersome repetitive large analyses. Therefore, CARD_management(), possible automate CARD copy/pasting CARD directory external temporary directory, like : result, run analysis, use: Take look CARD repository better understand CARD formatting.","code":"CARD_extraction(data %>% rename(Q=X),                 CARD_path=\"path/to/CARD\",                 CARD_dir=\"analyse_1\") CARD_management(CARD_path=\"path/to/CARD\",                 CARD_tmp=\"path/to/copy/CARD\",                 CARD_dir=\"analyse_1\",                 CARD_name=c(\"QA\", \"QJXA\"),                 overwrite=TRUE,                 verbose=TRUE) CARD_extraction(data %>% rename(Q=X),                 CARD_path=\"path/to/CARD\",                 CARD_tmp=\"path/to/copy/CARD\",                 CARD_dir=\"analyse_1\")"},{"path":"/index.html","id":"trend-analyse","dir":"","previous_headings":"Documentation","what":"Trend analyse","title":"EXstat","text":"stationarity analyse computed process_trend() function extracted data dataEX. statistical test used Mann-Kendall test12. Hence, following expression produces result tibble precises, among information, name time serie p value Theil-Sen’s slope34, row. Finaly, p value 0.1, previous time serie shows increasing linear trend can represented equation Y = 0.0260*X + b type error 10 % trust 90 %.","code":"trendEX = process_trend(data=dataEX) # A tibble: 1 × 12   ID      variable_en level H          p      a     b period_trend   <chr>   <chr>       <dbl> <lgl>  <dbl>  <dbl> <dbl> <list> 1 serie A X             0.1 TRUE  0.0958 0.0260  99.3 <date [2]>    mean_period_trend a_normalise a_normalise_min a_normalise_max   <lgl>                   <dbl>           <dbl>           <dbl> 1 NA                     0.0260          0.0260          0.0260"},{"path":"/index.html","id":"faq","dir":"","previous_headings":"","what":"FAQ","title":"EXstat","text":"question. Solution: Search existing issue list one similar question create new issue. found bug. Good Solution: Search existing issue list one reported create new issue. Better Solution: Along issue submission provide minimal reproducible example bug. Best Solution: Fix issue submit pull request. fastest way get bug fixed.","code":""},{"path":"/index.html","id":"code-of-conduct","dir":"","previous_headings":"","what":"Code of Conduct","title":"EXstat","text":"Please note project released Contributor Code Conduct. participating project agree abide terms.","code":""},{"path":"/reference/CARD_extraction.html","id":null,"dir":"Reference","previous_headings":"","what":"CARD_extraction — CARD_extraction","title":"CARD_extraction — CARD_extraction","text":"Extracts variables time series (example, yearly mean time series) using CARD parameterization files.","code":""},{"path":"/reference/CARD_extraction.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"CARD_extraction — CARD_extraction","text":"","code":"CARD_extraction(   data,   CARD_path = system.file(\"CARD\", package = \"EXstat\"),   CARD_tmp = NULL,   CARD_dir = \"__all__\",   CARD_name = NULL,   period_default = NULL,   suffix = NULL,   suffix_delimiter = \"_\",   cancel_lim = FALSE,   simplify = FALSE,   expand_overwrite = NULL,   sampling_period_overwrite = NULL,   rmNApct = TRUE,   rm_duplicates = FALSE,   dev = FALSE,   verbose = FALSE )"},{"path":"/reference/CARD_extraction.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"CARD_extraction — CARD_extraction","text":"data Input data format tibble tibble package. needs : one column Date regularly spaced unique time serie. one time serie, least one column needs character string names time series order identify . one column identifier given, used order identify unique time serie. least one column numeric (logical) process variable extraction perform. numerical column can leave useless, suppressed. e.g.   CARD_path character string representing path downloaded CARD directory (end \"CARD\"). directory, can copy paste (later modify) CARDs \"__all__\" subdirectory want use analysis represented subdirectory named CARD_dir (see CARD_tmp want locate CARD_dir directory elsewhere). CARDs, can specify functions available scripts \"__tools__\" subdirectory. CARD_tmp want locate CARD_dir directory somewhere CARD_path directory, can specify character string CARD_tmp path CARD_dir subdirectory CARDs searched. Default \"NULL\" want locate CARD_dir subdirectory CARDs CARD_path. CARD_dir character string name subdirectory CARD_path (CARD_tmp) CARD parameterization files located analysis. Default \"WIP\". CARD_name default, CARDs CARD_dir directory used analysis. However, can specify vector character strings names CARDs used. Default \"NULL\" using CARDs. period_default vector two dates (two unambiguous character strings can coerced dates) restrict period analysis. example, can c(\"1950-01-01\", \"2020-12-31\") select data 1st January 1950 end December 2020. default option period=NULL, considers available data time serie. suffix character string vector representing suffixes appended column names extracted variables. parameter allows handling multiple extraction scenarios. example, cumbersome case can unique function apply multiple list column. possible give funct=list(QA_obs=mean, QA_sim=mean) funct_args=list(list(\"Q_obs\", na.rm=TRUE), list(\"Q_sim\", na.rm=TRUE)) simply funct=list(QA=mean) funct_args=list(\"Q\", na.rm=TRUE) suffix=c(\"obs\", \"sim\"). two approach give result. Default NULL. suffix_delimiter character string specifies delimiter use variable name suffix NULL. default \"_\". cancel_lim logical specify whether cancel NA percentage limits CARDs. Default FALSE. simplify logical specify whether simplify extracted data joining tibble extracted CARDs. Usefull extracted variable temporal extension. Default \"FALSE\". expand_overwrite logical NULL. TRUE, expand output tibble list tibble extracted variable suffix. Default NULL conserve value specified CARDs used. sampling_period_overwrite character string vector two character strings indicate sample data time step defined time_step. Hence, choice argument needs link choice time step. example, yearly extraction time_step set \"year\", sampling_period needs formated %m-%d (month - day year) order indicate start sampling data current year. precisly, time_step=\"year\" sampling_period=\"03-19\", funct apply every data 3rd march year 2nd march following one. way, possible create sub-year sampling vector two character strings sampling_period=c(\"02-01\", \"07-31\") order process data date 1st february 31th jully year. available now monthly (seasonal) extraction, sampling_period needs give day month, example sampling_period=\"10\" extract data 10th month 9th following month. Default NULL conserve value specified CARDs used. rmNApct logical. NApct column, shows percentage missing values output, removed ? Default TRUE. rm_duplicates logical. duplicate time series values automatically removed ? Default FALSE. dev logical TRUE, development mode enabled. Default FALSE. verbose logical. intermediate messages printed execution function ? Default FALSE.","code":"> data A tibble: 201 × 4    time         Q_obs  Q_sim  ID    <date>       <dbl>  <dbl>  <chr> 1   2000-02-10   10     97.8  serie 1 2   2000-02-11   19    -20.5  serie 1 3   2000-02-12   13    -76.9  serie 1 4   2000-02-13   15    -86.0  serie 1     ... 103 2001-01-01  1.3     1988  serie 2 104 2001-01-02  1.2      109  serie 2 105 2001-01-03  1.0       90  serie 2 106 2001-01-04  1.1       91  serie 2     ..."},{"path":"/reference/CARD_extraction.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"CARD_extraction — CARD_extraction","text":"list two tibbles. dataEX tibble, contains extracted variable, named list tibbles extracted variable expand_overwrite TRUE. metaEX tibble, contains metadata extraction CARDs.","code":""},{"path":[]},{"path":"/reference/CARD_extraction.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"CARD_extraction — CARD_extraction","text":"","code":"## Creation of random data set set.seed(99) Start = as.Date(\"2000-02-01\") End = as.Date(\"2010-04-04\") Date = seq.Date(Start, End, by=\"day\")  # First time serie data_1 = dplyr::tibble(time=Date,                        X_state1=as.numeric(Date) +                            rnorm(length(Date), 1e4, 1e3),                        X_state2=seq(1, length(Date))/1e2 +                            rnorm(length(Date), 0, 1),                        id=\"serie 1\") data_1$X_state2[round(runif(500, 1, nrow(data_1)))] = NA  # Second time serie data_2 = dplyr::tibble(time=Date,                        X_state1=as.numeric(Date) +                            rnorm(length(Date), 1e4, 1e3),                        X_state2=seq(1, length(Date))/1e2 +                            rnorm(length(Date), 0, 1),                        id=\"serie 2\") data_2$X_state2[round(runif(1000, 1, nrow(data_2)))] = NA  # Final data for testing data = dplyr::bind_rows(data_1, data_2)  ## Extraction with CARD # Copy and paste CARD from __all__ to the CARD_dir directory (or # use CARD_tmp with CARD_management function) and then process the # extraction if (FALSE) { # \\dontrun{ CARD_extraction(data,                 CARD_path=\"path/to/CARD\",                 CARD_tmp=\"path/to/temporary\",                 CARD_dir=\"WIP\",                 period_default=c(\"1950-01-01\", \"2020-12-31\"),                 simplify=FALSE,                 cancel_lim=TRUE,                 verbose=TRUE) } # }"},{"path":"/reference/CARD_management.html","id":null,"dir":"Reference","previous_headings":"","what":"CARD_management — CARD_management","title":"CARD_management — CARD_management","text":"Manage CARD directory structure performing automatic file operations copy paste CARD parameterization files efficiently.","code":""},{"path":"/reference/CARD_management.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"CARD_management — CARD_management","text":"","code":"CARD_management(   CARD_path = system.file(\"CARD\", package = \"EXstat\"),   CARD_tmp = tempfile(),   CARD_dir = \"WIP\",   CARD_name = c(\"QA\", \"QJXA\"),   layout = c(CARD_dir, \"[\", CARD_name, \"]\"),   underscore_to_white = TRUE,   add_id = TRUE,   overwrite = TRUE,   verbose = FALSE,   args = list(CARD_path = CARD_path, CARD_tmp = CARD_tmp, layout = layout,     underscore_to_white = underscore_to_white, add_id = add_id, overwrite = overwrite,     verbose = verbose) )"},{"path":"/reference/CARD_management.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"CARD_management — CARD_management","text":"CARD_path character string representing path downloaded CARD directory (end \"CARD\"). directory, can search CARDs want \"__all__\" subdirectory use analysis (see layout know specify CARD want). CARD_tmp character string path directory CARD parameterization files copied pasted analysis. Default NULL want use tmp subdirectory CARD_path directory. CARD_dir character string name subdirectory CARD_path (CARD_tmp) CARD parameterization files located analysis. Default \"WIP\". CARD_name vector character strings names CARDs used. Default c(\"QA\", \"QJXA\"). layout character string vector specifying tree structure files want analysis. element vector represents either: name analysis directory (e.g., \"WIP\") beginning ending analysis directory: \"[\" start \"]\" end CARD name (e.g., \"QA\") example, want create \"WIP\" analysis directory CARDs named \"QA\" \"QJXA\", can provide c(\"WIP\", \"[\", \"QA\", \"QJXA\", \"]\"). Default NULL use CARD_dir CARD_name. underscore_to_white logical. TRUE, underscores directory names replaced spaces. Default TRUE. add_id logical. TRUE, numerical IDs added start copied pasted CARD names maintain input order. Default TRUE. overwrite logical. TRUE, existing CARD files CARD_tmp directory overwritten. Default TRUE. verbose logical. intermediate messages printed execution function ? Default FALSE. args intermediate form arguments useful argparse package used. provided, automatically created using function arguments. Default NULL.","code":""},{"path":"/reference/CARD_management.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"CARD_management — CARD_management","text":"CARD parameterization files copied pasted CARD_path organized according structure given layout CARD_tmp directory.","code":""},{"path":[]},{"path":"/reference/CARD_management.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"CARD_management — CARD_management","text":"","code":"if (FALSE) { # \\dontrun{ CARD_management(CARD_path=\"path/to/CARD\",                 CARD_tmp=\"path/to/copy/CARD\",                 CARD_dir=\"WIP\",                 CARD_name=c(\"QA\", \"QJXA\"),                 overwrite=TRUE,                 verbose=TRUE) # or with layout CARD_management(CARD_path=\"path/to/CARD\",                 CARD_tmp=\"path/to/copy/CARD\",                 layout=c(\"WIP\", \"[\", \"QA\", \"QJXA\", \"]\"),                 overwrite=TRUE,                 verbose=TRUE) } # }"},{"path":"/reference/CARD_transpose_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Transpose dataEX data.frame returned by CARD_extraction — CARD_transpose_data","title":"Transpose dataEX data.frame returned by CARD_extraction — CARD_transpose_data","text":"Transpose dataEX data.frame returned CARD_extraction","code":""},{"path":"/reference/CARD_transpose_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Transpose dataEX data.frame returned by CARD_extraction — CARD_transpose_data","text":"","code":"CARD_transpose_data(dataEX)"},{"path":"/reference/CARD_transpose_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Transpose dataEX data.frame returned by CARD_extraction — CARD_transpose_data","text":"dataEX data.frame returned CARD_extraction argument simplify=TRUE","code":""},{"path":"/reference/CARD_transpose_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Transpose dataEX data.frame returned by CARD_extraction — CARD_transpose_data","text":"transposed data frame first column 'name' following columns ID time series.","code":""},{"path":"/reference/EXstat.html","id":null,"dir":"Reference","previous_headings":"","what":"EXstat — EXstat","title":"EXstat — EXstat","text":"Provides efficient simple solution aggregate analyze stationarity time series.","code":""},{"path":"/reference/EXstat.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"EXstat — EXstat","text":"See EXstat github documentation https://github.com/super-lou/EXstat easier approach. user-friendly interaction, package developed symbiosis predefined parameter files called CARD https://github.com/super-lou/CARD/. define complex parameters extract hydroclimatological variables. , CARD want exist, easy create one based others.","code":""},{"path":[]},{"path":"/reference/EXstat.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"EXstat — EXstat","text":"Main Developer Maintainer Louis Héraut louis.heraut@inrae.fr INRAE Developer Benjamin Renard benjamin.renard@inrae.fr INRAE Valentin Mansanarez Contributors Éric Sauquet eric.sauquet@inrae.fr INRAE Jean-Philippe Vidal jean-philippe.vidal@inrae.fr INRAE Nathan Pellerin","code":""},{"path":"/reference/GeneralMannKendall_WRAP.html","id":null,"dir":"Reference","previous_headings":"","what":"Mann-Kendall trend analysis commit 1 — GeneralMannKendall_WRAP","title":"Mann-Kendall trend analysis commit 1 — GeneralMannKendall_WRAP","text":"Apply generalMannKendall function serie X.","code":""},{"path":"/reference/GeneralMannKendall_WRAP.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mann-Kendall trend analysis commit 1 — GeneralMannKendall_WRAP","text":"","code":"GeneralMannKendall_WRAP(   X,   level = 0.1,   time_dependency_option = \"INDE\",   DoDetrending = TRUE,   show_advance_stat = FALSE,   verbose = FALSE )"},{"path":"/reference/GeneralMannKendall_WRAP.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mann-Kendall trend analysis commit 1 — GeneralMannKendall_WRAP","text":"X data (vector). IMPORTANT: assumes X regularly-spaced. level numeric Mann-Kendall test significance level 0 1. Default 0.1. time_dependency_option character string handling temporal dependence Mann-Kendall test. Possible values : \"INDE\", assume independence (.e. standard MK test) \"AR1\", assumes AR1 short-term dependence structure (.e. Hamed Rao's version MK test) \"LTP\", assume long-term persistence (.e. Hamed's version MK test) DoDetrending, logical, used dep.option == LTP: detrending estimating Hurst coefficient (default=TRUE recommended Hamed's paper) show_advance_stat logical Whether display advanced statistical details. Default FALSE. verbose logical Whether print intermediate messages. Default FALSE.","code":""},{"path":"/reference/GeneralMannKendall_WRAP.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mann-Kendall trend analysis commit 1 — GeneralMannKendall_WRAP","text":"dataframe, different statistics values interest test.","code":""},{"path":"/reference/GeneralMannKendall_WRAP.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mann-Kendall trend analysis commit 1 — GeneralMannKendall_WRAP","text":"","code":"if (FALSE) { # \\dontrun{ GeneralMannKendall_WRAP(X=1:100) GeneralMannKendall_WRAP(X=rep(1, 100)) } # }"},{"path":"/reference/HurstLkh.html","id":null,"dir":"Reference","previous_headings":"","what":"Hurst likelihood — HurstLkh","title":"Hurst likelihood — HurstLkh","text":"Compute likelihood function maximized estimating Hurst coefficient H","code":""},{"path":"/reference/HurstLkh.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hurst likelihood — HurstLkh","text":"","code":"HurstLkh(H, x)"},{"path":"/reference/HurstLkh.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hurst likelihood — HurstLkh","text":"H numeric,  hurst coeff. value x, data sample","code":""},{"path":"/reference/HurstLkh.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Hurst likelihood — HurstLkh","text":"log-likelihood value","code":""},{"path":"/reference/HurstLkh.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Hurst likelihood — HurstLkh","text":"","code":"if (FALSE) { # \\dontrun{ data(nhtemp) # Average Yearly Temperatures in New Haven HurstLkh(H=0.8, x=nhtemp) HurstLkh(H=0.5, x=nhtemp) HurstLkh(H=0.2, x=nhtemp) } # }"},{"path":"/reference/estimateHurst.html","id":null,"dir":"Reference","previous_headings":"","what":"Hurst coefficient — estimateHurst","title":"Hurst coefficient — estimateHurst","text":"Estimate Hurst coefficient series","code":""},{"path":"/reference/estimateHurst.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hurst coefficient — estimateHurst","text":"","code":"estimateHurst(Z, DoDetrending = TRUE, trend = getMKStat(Z)$trend)"},{"path":"/reference/estimateHurst.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hurst coefficient — estimateHurst","text":"Z numeric, data (NA-free) DoDetrending logical, detrend data estimating Hurst? trend numeric, trend value (used detrending required)","code":""},{"path":"/reference/estimateHurst.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Hurst coefficient — estimateHurst","text":"estimated value hurst coefficient","code":""},{"path":"/reference/estimateHurst.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Hurst coefficient — estimateHurst","text":"","code":"if (FALSE) { # \\dontrun{ data(nhtemp) #Average Yearly Temperatures in New Haven estimateHurst(Z=nhtemp) } # }"},{"path":"/reference/fieldSignificance_FDR.html","id":null,"dir":"Reference","previous_headings":"","what":"FDR field significance — fieldSignificance_FDR","title":"FDR field significance — fieldSignificance_FDR","text":"Field significance using false detection rate approach","code":""},{"path":"/reference/fieldSignificance_FDR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"FDR field significance — fieldSignificance_FDR","text":"","code":"fieldSignificance_FDR(pvals, level = 0.1)"},{"path":"/reference/fieldSignificance_FDR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"FDR field significance — fieldSignificance_FDR","text":"pvals numeric vector, p-values local tests level numeric (0, 1), level field significance evaluated","code":""},{"path":"/reference/fieldSignificance_FDR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"FDR field significance — fieldSignificance_FDR","text":"pFDR, FDR p-value, interpreted follows: local p-values smaller pFDR field-significant.","code":""},{"path":"/reference/fieldSignificance_FDR.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"FDR field significance — fieldSignificance_FDR","text":"Benjamini, Y., Y. Hochberg (1995), Controlling false discovery rate: practical powerful approach multiple testing, J. R. Stat. Soc., Ser. B., 57, 289–300.","code":""},{"path":"/reference/fieldSignificance_FDR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"FDR field significance — fieldSignificance_FDR","text":"","code":"if (FALSE) { # \\dontrun{ set.seed(123456) # Make example reproducible level = 0.1 # Level of the test data(nhtemp) # Average Yearly Temperatures in New Haven # Add 29 stationary series to nhtemp series X = matrix(c(nhtemp, rnorm(length(nhtemp)*29)),              nrow=length(nhtemp)) # Compute local p-values from a MK test pvals = rep(NA, 30) for (i in 1:30) {     pvals[i] = generalMannKendall(X[, i], level=level)$P } # Evaluate field significance pFDR = fieldSignificance_FDR(pvals, level) which(pvals <= level) # Locally-significant sites which(pvals <= pFDR) # FDR-significant sites } # }"},{"path":"/reference/generalMannKendall.html","id":null,"dir":"Reference","previous_headings":"","what":"General Mann-Kendall — generalMannKendall","title":"General Mann-Kendall — generalMannKendall","text":"general version Mann-Kendall test, enabling various dependence assumptions.","code":""},{"path":"/reference/generalMannKendall.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"General Mann-Kendall — generalMannKendall","text":"","code":"generalMannKendall(   X,   level = 0.1,   dep.option = \"INDE\",   DoDetrending = TRUE,   verbose = FALSE )"},{"path":"/reference/generalMannKendall.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"General Mann-Kendall — generalMannKendall","text":"X numeric vector, data. IMPORTANT: X assumed regularly-spaced. uses NA fill gaps rather removing missing values. level numeric (0,1), level test. dep.option string, option handling temporal dependence. Available : 'INDE', assume independence (.e. standard MK test) 'AR1', assumes AR1 short-term dependence structure (.e. Hamed Rao's version MK test) 'LTP', assume long-term persistence (.e. Hamed's version MK test) DoDetrending, logical, used dep.option == LTP: detrending estimating Hurst coefficient (default=TRUE recommended Hamed's paper) verbose logical Whether print intermediate messages. Default FALSE.","code":""},{"path":"/reference/generalMannKendall.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"General Mann-Kendall — generalMannKendall","text":"list following fields : H: logical, reject (true) reject (false) H0 P: p-value test STAT: test statistics TREND: trend estimate (using Sen's slope estimate) DEP: dependence estimate (= 0 dep.option='INDE', =lag-1 autocorrelation dep.option='AR1', =Hurst coefficient dep.option='LTP')","code":""},{"path":"/reference/generalMannKendall.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"General Mann-Kendall — generalMannKendall","text":"Handling ties: Specific formula exist INDE AR1, LTP case trickier. Hammed's paper unclear handle ties, especially step Hurst coefficient estimation. normal-score transformation step, one needs decide assign rank ties. implemented option ties.method = \"random\", .e. rank randomized ties. , strictly speaking, correct randomization impacts dependence structure. However synthetic runs suggest works OK. Computational efficiency: Likely poor case dep.option='LTP'. 4-level loop leads n^4 algorithm. attempted vectorize loop improve things => Expect significant running times dep.option='LTP ' size(X) > 50... (orders magnitude: 1s n=30, 10s n=50, 2-3 minutes n=100). hand options INDE AR1 fast.","code":""},{"path":"/reference/generalMannKendall.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"General Mann-Kendall — generalMannKendall","text":"Hamed, Rao, 1998. modified Mann-Kendall trend test autocorrelated data. J. Hydrol., 204(1-4): 182-196. Hamed, 2008. Trend detection hydrologic data: Mann-Kendall trend test scaling hypothesis. J. Hydrol., 349(3-4): 350-363.","code":""},{"path":"/reference/generalMannKendall.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"General Mann-Kendall — generalMannKendall","text":"","code":"if (FALSE) { # \\dontrun{ data(nhtemp) #Average Yearly Temperatures in New Haven generalMannKendall(X=nhtemp, dep.option='AR1') } # }"},{"path":"/reference/getAR1Correction.html","id":null,"dir":"Reference","previous_headings":"","what":"AR(1) correction — getAR1Correction","title":"AR(1) correction — getAR1Correction","text":"Compute correction variance MK statistics account AR(1) autocorrelation","code":""},{"path":"/reference/getAR1Correction.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"AR(1) correction — getAR1Correction","text":"","code":"getAR1Correction(Z)"},{"path":"/reference/getAR1Correction.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"AR(1) correction — getAR1Correction","text":"Z numeric, data (NA-free)","code":""},{"path":"/reference/getAR1Correction.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"AR(1) correction — getAR1Correction","text":"list components: $lag1 (estimated lag-1 correlation coefficient) $correction (correction variance MK stat)","code":""},{"path":"/reference/getAR1Correction.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"AR(1) correction — getAR1Correction","text":"","code":"if (FALSE) { # \\dontrun{ data(nhtemp) # Average Yearly Temperatures in New Haven getAR1Correction(Z=nhtemp) getAR1Correction(rnorm(100)) } # }"},{"path":"/reference/getMKStat.html","id":null,"dir":"Reference","previous_headings":"","what":"Mann-Kendall statistics — getMKStat","title":"Mann-Kendall statistics — getMKStat","text":"Compute MK stat Sen's trend estimate","code":""},{"path":"/reference/getMKStat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mann-Kendall statistics — getMKStat","text":"","code":"getMKStat(X)"},{"path":"/reference/getMKStat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mann-Kendall statistics — getMKStat","text":"X numeric, data","code":""},{"path":"/reference/getMKStat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mann-Kendall statistics — getMKStat","text":"list, components: $stat, MK statistics; $trend, Sen's estimate.","code":""},{"path":"/reference/getMKStat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mann-Kendall statistics — getMKStat","text":"","code":"if (FALSE) { # \\dontrun{ data(nhtemp) #Average Yearly Temperatures in New Haven getMKStat(X = nhtemp) } # }"},{"path":"/reference/getTiesCorrection.html","id":null,"dir":"Reference","previous_headings":"","what":"Ties correction — getTiesCorrection","title":"Ties correction — getTiesCorrection","text":"Compute correction variance MK statistics account ties","code":""},{"path":"/reference/getTiesCorrection.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Ties correction — getTiesCorrection","text":"","code":"getTiesCorrection(Z)"},{"path":"/reference/getTiesCorrection.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Ties correction — getTiesCorrection","text":"Z numeric, data (NA-free)","code":""},{"path":"/reference/getTiesCorrection.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Ties correction — getTiesCorrection","text":"correction variance MK stat","code":""},{"path":"/reference/getTiesCorrection.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Ties correction — getTiesCorrection","text":"","code":"if (FALSE) { # \\dontrun{ data(nhtemp) # Average Yearly Temperatures in New Haven getTiesCorrection(Z=nhtemp) getTiesCorrection(rnorm(100)) } # }"},{"path":"/reference/process_extraction.html","id":null,"dir":"Reference","previous_headings":"","what":"process_extraction — process_extraction","title":"process_extraction — process_extraction","text":"Extracts variable time series (example yearly mean time series). Extraction can specific time step sampled differently along time step.","code":""},{"path":"/reference/process_extraction.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"process_extraction — process_extraction","text":"","code":"process_extraction(   data,   funct = max,   funct_args = list(),   time_step = \"year\",   sampling_period = NULL,   period = NULL,   is_date = FALSE,   NApct_lim = NULL,   NAyear_lim = NULL,   Seasons = c(\"DJF\", \"MAM\", \"JJA\", \"SON\"),   nameEX = \"X\",   suffix = NULL,   suffix_delimiter = \"_\",   keep = NULL,   compress = FALSE,   expand = FALSE,   rmNApct = TRUE,   rm_duplicates = FALSE,   dev = FALSE,   verbose = FALSE )"},{"path":"/reference/process_extraction.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"process_extraction — process_extraction","text":"data Input data format tibble tibble package. needs : one column Date regularly spaced unique time serie. one time serie, least one column needs character string names time series order identify . one column identifier given, used order identify unique time serie. least one column numeric (logical) process variable extraction perform. numerical column can leave useless, suppressed. e.g.   funct function want use process variable extraction. specificaly, possible give list several functions element list name used extracted column names element function previously defined list. simple case funct=mean complicated one funct=list(QA=mean, QJXA=max). Default max. funct_args list list named arguments needed functions provided funct. list can simple list one function given funct. argument can relate column name order specify numerical column extraction perfom. simple example, funct_args=list(\"Q_obs\", na.rm=TRUE) complex case funct_args=list(list(\"Q_obs\", na.rm=TRUE), list(\"Q_sim\", na.rm=FALSE)). Default list. time_step character string specifying time step variable extraction process. Possible values : \"year\" value per year \"month\" value month year (12 values least full year given) \"year-month\" value month year (12 times number given year values end) \"season\" value season th year (default 4 values) \"year-season\" value season year (default 4 times number given year values end) \"yearday\" one value per day year (365 values end least full year given... one year seems obviously interesting) \"none\" want extract unique value whole time serie Default \"year\". sampling_period character string vector two characters strings indicate sample data time step defined time_step. Hence, choice argument needs link choice time step. example, yearly extraction time_step set \"year\", sampling_period needs formated %m-%d (month - day year) order indicate start sampling data current year. precisly, time_step=\"year\" sampling_period=\"03-19\", funct apply every data 3rd march year 2nd march following one. way, possible create sub-year sampling vector two character strings sampling_period=c(\"02-01\", \"07-31\") order process data date 1st february 31th jully year. available now monthly (seasonal) extraction, sampling_period needs give day month, example sampling_period=\"10\" extract data 10th month 9th following month. Default NULL. period vector two dates (two unambiguous character strings can coerced dates) restrict period analysis. example, can c(\"1950-01-01\", \"2020-12-31\") select data 1st January 1950 end December 2020. default option period=NULL, considers available data time serie. is_date logical. TRUE, process_extration() convert result application funct day year. aim example give funct=.min is_date=TRUE, result indice minimum sample associated day year given integer (1 1st january). Default FALSE. NApct_lim numeric. maximum percentage missing values sample allowed. threshold exceeded, value associated current sample convert NA. Default NULL. NAyear_lim numeric.maximum number continuous missing years allowed. threshold exceeded, time serie split half around problematic period longest part used extraction process. Default NULL. Seasons vector character strings indicates seasonal pattern year. months year needs contain Seasons variable. Give months circulary vector element character chain several months identify first letter names. default Seasons=c(\"DJF\", \"MAM\", \"JJA\", \"SON\") can set example Seasons=c(\"MAMJJA\", \"SONDJF\"). nameEX character string specifying name column extracted variable name given funct. Default \"X\". suffix character string vector representing suffixes appended column names extracted variables. parameter allows handling multiple extraction scenarios. example, cumbersome case can unique function apply multiple list column. possible give funct=list(QA_obs=mean, QA_sim=mean) funct_args=list(list(\"Q_obs\", na.rm=TRUE), list(\"Q_sim\", na.rm=TRUE)) simply funct=list(QA=mean) funct_args=list(\"Q\", na.rm=TRUE) suffix=c(\"obs\", \"sim\"). two approach give result. Default NULL. suffix_delimiter character string specifies delimiter use variable name suffix NULL. default \"_\". keep developpement character string vector column names keep output tibble. current state, keep can set NULL want keep anythings output besides usefull column, \"\" want conserve initial column output column. Warning : number rows output keep=\"\" , result, input. example, extracted value year daily time series assigned first day year, NaN assigned every value output. Default NULL. compress logical. time_step set \"month\", \"year-month\", \"season\" \"year-season\" function return standard tibble compressed one ?  compress = TRUE, function perform pivot_wider operation display month season information columns instead rows. Default FALSE. e.g.   expand logical. TRUE, expand output tibble list tibble extracted variable suffix. Default FALSE. rmNApct logical. NApct column, shows percentage missing values output, removed ? Default TRUE. rm_duplicates logical. duplicate time series values automatically removed ? Default FALSE. dev logical TRUE, development mode enabled. Default FALSE. verbose logical. intermediate messages printed execution function ? Default FALSE.","code":"> data A tibble: 201 × 4    time         Q_obs  Q_sim  ID    <date>       <dbl>  <dbl>  <chr> 1   2000-02-10   10     97.8  serie 1 2   2000-02-11   19    -20.5  serie 1 3   2000-02-12   13    -76.9  serie 1 4   2000-02-13   15    -86.0  serie 1     ... 103 2001-01-01  1.3     1988  serie 2 104 2001-01-02  1.2      109  serie 2 105 2001-01-03  1.0       90  serie 2 106 2001-01-04  1.1       91  serie 2     ... # for time_step=\"season\" and compress=FALSE # A tibble: 8 × 4   ID       <time    Q    NApct   <chr>    <chr>  <dbl>  <dbl> 1 serie 1  DJF    1464    8.6 2 serie 1  JJA    1447    0 3 serie 1  MAM    1395    0 4 serie 1  SON    1458    0 5 serie 2  DJF      11    8.6 6 serie 2  JJA       2    0 7 serie 2  MAM       1    0 8 serie 2  SON       4    0  # for time_step=\"season\" and compress=TRUE # A tibble: 2 × 5  ID       Q_DJF  Q_JJA  Q_MAM  Q_SON  <chr>    <dbl>  <dbl>  <dbl>  <dbl> 1 serie 1  1464  1447   1395   1458 2 serie 2    11     2      1      4"},{"path":"/reference/process_extraction.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"process_extraction — process_extraction","text":"tibble containing extracted variable, named list tibble extracted variable expand TRUE. output follows format input data described data, making possible iterate output using process_extraction().","code":""},{"path":"/reference/process_extraction.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"process_extraction — process_extraction","text":"compress expand set TRUE time_step set \"year-month\" \"year-season\". NA values considered missing values used compute percentage gaps time step, potentially removing results percentage exceeds NApct_lim. NaN values considered non-existent values can also computation artifacts, example, keep option used. speed performance reasons, NaN values needed masked values input time series daily extracted throughout year.","code":""},{"path":[]},{"path":"/reference/process_extraction.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"process_extraction — process_extraction","text":"","code":"## Creation of random data set set.seed(99) Start = as.Date(\"2000-02-01\") End = as.Date(\"2010-04-04\") Date = seq.Date(Start, End, by=\"day\")  # First time serie data_1 = dplyr::tibble(time=Date,                        X_state1=as.numeric(Date) +                            rnorm(length(Date), 1e4, 1e3),                        X_state2=seq(1, length(Date))/1e2 +                            rnorm(length(Date), 0, 1),                        id=\"serie 1\") data_1$X_state2[round(runif(500, 1, nrow(data_1)))] = NA  # Second time serie data_2 = dplyr::tibble(time=Date,                        X_state1=as.numeric(Date) +                            rnorm(length(Date), 1e4, 1e3),                        X_state2=seq(1, length(Date))/1e2 +                            rnorm(length(Date), 0, 1),                        id=\"serie 2\") data_2$X_state2[round(runif(1000, 1, nrow(data_2)))] = NA  # Final data for testing data = dplyr::bind_rows(data_1, data_2)  ## Extraction of the yearly average of daily value. process_extraction(data=data,                    funct=list(XA_state1=mean),                    funct_args=list(\"X_state1\", na.rm=TRUE),                    time_step=\"year\") #> # A tibble: 22 × 3 #>    id      time       XA_state1 #>    <chr>   <date>         <dbl> #>  1 serie 1 2000-01-01    21092. #>  2 serie 1 2001-01-01    21468. #>  3 serie 1 2002-01-01    21895. #>  4 serie 1 2003-01-01    22232. #>  5 serie 1 2004-01-01    22656. #>  6 serie 1 2005-01-01    22999. #>  7 serie 1 2006-01-01    23357. #>  8 serie 1 2007-01-01    23605. #>  9 serie 1 2008-01-01    24223. #> 10 serie 1 2009-01-01    24421. #> # ℹ 12 more rows  ## Extraction of the median of the yearly maximum of the monthly # averages of daily values. # Three steps are needed for this case, the first one is the # monthly average over years. dataEX_tmp =     process_extraction(data=data,                        funct=list(X_month_state2=mean),                        funct_args=list(\"X_state2\", na.rm=TRUE),                        time_step=\"year-month\",                        NApct_lim=20,                        rmNApct=FALSE) # Missing values represented by NA are handled. print(dataEX_tmp) #> # A tibble: 246 × 4 #>    id      time       X_month_state2 NApct #>    <chr>   <date>              <dbl> <dbl> #>  1 serie 1 2000-02-01        -0.0883   6.6 #>  2 serie 1 2000-03-01         0.205    6.6 #>  3 serie 1 2000-04-01         0.837    6.6 #>  4 serie 1 2000-05-01         0.737    6.6 #>  5 serie 1 2000-06-01         1.35    19.7 #>  6 serie 1 2000-07-01         1.55     9.9 #>  7 serie 1 2000-08-01         2.39    16.4 #>  8 serie 1 2000-09-01         2.41    13.1 #>  9 serie 1 2000-10-01         2.56     9.9 #> 10 serie 1 2000-11-01        NA       23   #> # ℹ 236 more rows # In this second step, for the yearly maximum, the sampling period # for each year is modified to a fixed value. dataEX_tmp =     process_extraction(data=dataEX_tmp,                        funct=list(XX_state2=max),                        funct_args=list(\"X_month_state2\", na.rm=TRUE),                        sampling_period=c(\"05-01\", \"11-30\"),                        time_step=\"year\")  # Finaly, the median is computed process_extraction(data=dataEX_tmp,                    funct=list(med_XX_state2=median),                    funct_args=list(\"XX_state2\", na.rm=TRUE),                    time_step=\"none\") #> # A tibble: 2 × 2 #>   id      med_XX_state2 #>   <chr>           <dbl> #> 1 serie 1          19.3 #> 2 serie 2          18.7  ## Extraction of the monthly average and the monthly maximum in a # single call. # The output is in long tibble format with 12 values for each time # serie. process_extraction(data=data,                    funct=list(XA_state1=mean,                               XX_state2=max),                    funct_args=list(list(\"X_state1\", na.rm=TRUE),                                    list(\"X_state2\", na.rm=TRUE)),                    time_step=\"month\") #> # A tibble: 24 × 5 #>    id      time       Month XA_state1 XX_state2 #>    <chr>   <date>     <dbl>     <dbl>     <dbl> #>  1 serie 1 2000-01-01     1    22997.      38.3 #>  2 serie 1 2000-02-01     2    22933.      39.0 #>  3 serie 1 2000-03-01     3    22815.      40.0 #>  4 serie 1 2000-04-01     4    22774.      37.7 #>  5 serie 1 2000-05-01     5    22716.      35.4 #>  6 serie 1 2000-06-01     6    22747.      36.6 #>  7 serie 1 2000-07-01     7    22805.      36.5 #>  8 serie 1 2000-08-01     8    22755.      36.9 #>  9 serie 1 2000-09-01     9    22867.      37.1 #> 10 serie 1 2000-10-01    10    22921.      38.3 #> # ℹ 14 more rows # In this case, the output tibble is compress to have the date # indication in column. This also works for year-month extraction. process_extraction(data=data,                    funct=list(XA_state1=mean,                               XX_state2=max),                    funct_args=list(list(\"X_state1\", na.rm=TRUE),                                    list(\"X_state2\", na.rm=TRUE)),                    time_step=\"month\",                    compress=TRUE) #> # A tibble: 2 × 25 #>   id      XA_state1_jan XA_state1_feb XA_state1_mar XA_state1_apr XA_state1_may #>   <chr>           <dbl>         <dbl>         <dbl>         <dbl>         <dbl> #> 1 serie 1        22997.        22933.        22815.        22774.        22716. #> 2 serie 2        23007.        22869.        22925.        22724.        22785. #> # ℹ 19 more variables: XA_state1_jun <dbl>, XA_state1_jul <dbl>, #> #   XA_state1_aug <dbl>, XA_state1_sep <dbl>, XA_state1_oct <dbl>, #> #   XA_state1_nov <dbl>, XA_state1_dec <dbl>, XX_state2_jan <dbl>, #> #   XX_state2_feb <dbl>, XX_state2_mar <dbl>, XX_state2_apr <dbl>, #> #   XX_state2_may <dbl>, XX_state2_jun <dbl>, XX_state2_jul <dbl>, #> #   XX_state2_aug <dbl>, XX_state2_sep <dbl>, XX_state2_oct <dbl>, #> #   XX_state2_nov <dbl>, XX_state2_dec <dbl> # And in this last case, the output tibble is compress and then # expand in order to have a list of tibble for each variable. process_extraction(data=data,                    funct=list(XA_state1=mean,                               XX_state2=max),                    funct_args=list(list(\"X_state1\", na.rm=TRUE),                                    list(\"X_state2\", na.rm=TRUE)),                    time_step=\"month\",                    compress=TRUE,                    expand=TRUE) #> $XA_state1_jan #> # A tibble: 2 × 2 #>   id      XA_state1_jan #>   <chr>           <dbl> #> 1 serie 1        22997. #> 2 serie 2        23007. #>  #> $XA_state1_feb #> # A tibble: 2 × 2 #>   id      XA_state1_feb #>   <chr>           <dbl> #> 1 serie 1        22933. #> 2 serie 2        22869. #>  #> $XA_state1_mar #> # A tibble: 2 × 2 #>   id      XA_state1_mar #>   <chr>           <dbl> #> 1 serie 1        22815. #> 2 serie 2        22925. #>  #> $XA_state1_apr #> # A tibble: 2 × 2 #>   id      XA_state1_apr #>   <chr>           <dbl> #> 1 serie 1        22774. #> 2 serie 2        22724. #>  #> $XA_state1_may #> # A tibble: 2 × 2 #>   id      XA_state1_may #>   <chr>           <dbl> #> 1 serie 1        22716. #> 2 serie 2        22785. #>  #> $XA_state1_jun #> # A tibble: 2 × 2 #>   id      XA_state1_jun #>   <chr>           <dbl> #> 1 serie 1        22747. #> 2 serie 2        22771. #>  #> $XA_state1_jul #> # A tibble: 2 × 2 #>   id      XA_state1_jul #>   <chr>           <dbl> #> 1 serie 1        22805. #> 2 serie 2        22832. #>  #> $XA_state1_aug #> # A tibble: 2 × 2 #>   id      XA_state1_aug #>   <chr>           <dbl> #> 1 serie 1        22755. #> 2 serie 2        22858. #>  #> $XA_state1_sep #> # A tibble: 2 × 2 #>   id      XA_state1_sep #>   <chr>           <dbl> #> 1 serie 1        22867. #> 2 serie 2        22805. #>  #> $XA_state1_oct #> # A tibble: 2 × 2 #>   id      XA_state1_oct #>   <chr>           <dbl> #> 1 serie 1        22921. #> 2 serie 2        22824. #>  #> $XA_state1_nov #> # A tibble: 2 × 2 #>   id      XA_state1_nov #>   <chr>           <dbl> #> 1 serie 1        22930. #> 2 serie 2        22854. #>  #> $XA_state1_dec #> # A tibble: 2 × 2 #>   id      XA_state1_dec #>   <chr>           <dbl> #> 1 serie 1        22995. #> 2 serie 2        22954. #>  #> $XX_state2_jan #> # A tibble: 2 × 2 #>   id      XX_state2_jan #>   <chr>           <dbl> #> 1 serie 1          38.3 #> 2 serie 2          37.8 #>  #> $XX_state2_feb #> # A tibble: 2 × 2 #>   id      XX_state2_feb #>   <chr>           <dbl> #> 1 serie 1          39.0 #> 2 serie 2          38.3 #>  #> $XX_state2_mar #> # A tibble: 2 × 2 #>   id      XX_state2_mar #>   <chr>           <dbl> #> 1 serie 1          40.0 #> 2 serie 2          39.1 #>  #> $XX_state2_apr #> # A tibble: 2 × 2 #>   id      XX_state2_apr #>   <chr>           <dbl> #> 1 serie 1          37.7 #> 2 serie 2          37.1 #>  #> $XX_state2_may #> # A tibble: 2 × 2 #>   id      XX_state2_may #>   <chr>           <dbl> #> 1 serie 1          35.4 #> 2 serie 2          36.2 #>  #> $XX_state2_jun #> # A tibble: 2 × 2 #>   id      XX_state2_jun #>   <chr>           <dbl> #> 1 serie 1          36.6 #> 2 serie 2          35.3 #>  #> $XX_state2_jul #> # A tibble: 2 × 2 #>   id      XX_state2_jul #>   <chr>           <dbl> #> 1 serie 1          36.5 #> 2 serie 2          36.7 #>  #> $XX_state2_aug #> # A tibble: 2 × 2 #>   id      XX_state2_aug #>   <chr>           <dbl> #> 1 serie 1          36.9 #> 2 serie 2          36.9 #>  #> $XX_state2_sep #> # A tibble: 2 × 2 #>   id      XX_state2_sep #>   <chr>           <dbl> #> 1 serie 1          37.1 #> 2 serie 2          37.4 #>  #> $XX_state2_oct #> # A tibble: 2 × 2 #>   id      XX_state2_oct #>   <chr>           <dbl> #> 1 serie 1          38.3 #> 2 serie 2          36.8 #>  #> $XX_state2_nov #> # A tibble: 2 × 2 #>   id      XX_state2_nov #>   <chr>           <dbl> #> 1 serie 1          37.1 #> 2 serie 2          37.7 #>  #> $XX_state2_dec #> # A tibble: 2 × 2 #>   id      XX_state2_dec #>   <chr>           <dbl> #> 1 serie 1          38.3 #> 2 serie 2          37.6 #>   ## Extraction of the seasonal average and season maxium for both # columns using suffixes to avoid repetition with compress and # expand formating. process_extraction(data=data,                    funct=list(XA=mean,                               XX=max),                    funct_args=list(list(\"X\", na.rm=TRUE),                                    list(\"X\", na.rm=TRUE)),                    suffix=c(\"state1\", \"state2\"),                    time_step=\"season\",                    compress=TRUE,                    expand=TRUE) #> $XA_MAM #> # A tibble: 2 × 3 #>   id      XA_MAM_state1 XA_MAM_state2 #>   <chr>           <dbl>         <dbl> #> 1 serie 1        22770.          17.8 #> 2 serie 2        22816.          18.1 #>  #> $XA_JJA #> # A tibble: 2 × 3 #>   id      XA_JJA_state1 XA_JJA_state2 #>   <chr>           <dbl>         <dbl> #> 1 serie 1        22769.          18.0 #> 2 serie 2        22821.          18.1 #>  #> $XA_SON #> # A tibble: 2 × 3 #>   id      XA_SON_state1 XA_SON_state2 #>   <chr>           <dbl>         <dbl> #> 1 serie 1        22906.          18.9 #> 2 serie 2        22828.          19.0 #>  #> $XA_DJF #> # A tibble: 2 × 3 #>   id      XA_DJF_state1 XA_DJF_state2 #>   <chr>           <dbl>         <dbl> #> 1 serie 1        22975.          19.4 #> 2 serie 2        22943.          19.3 #>  #> $XX_MAM #> # A tibble: 2 × 3 #>   id      XX_MAM_state1 XX_MAM_state2 #>   <chr>           <dbl>         <dbl> #> 1 serie 1        27793.          40.0 #> 2 serie 2        26743.          39.1 #>  #> $XX_JJA #> # A tibble: 2 × 3 #>   id      XX_JJA_state1 XX_JJA_state2 #>   <chr>           <dbl>         <dbl> #> 1 serie 1        27388.          36.9 #> 2 serie 2        27411.          36.9 #>  #> $XX_SON #> # A tibble: 2 × 3 #>   id      XX_SON_state1 XX_SON_state2 #>   <chr>           <dbl>         <dbl> #> 1 serie 1        26734.          38.3 #> 2 serie 2        26829.          37.7 #>  #> $XX_DJF #> # A tibble: 2 × 3 #>   id      XX_DJF_state1 XX_DJF_state2 #>   <chr>           <dbl>         <dbl> #> 1 serie 1        27316.          39.0 #> 2 serie 2        28217.          38.3 #>"},{"path":"/reference/process_trend.html","id":null,"dir":"Reference","previous_headings":"","what":"process_trend — process_trend","title":"process_trend — process_trend","text":"Process trend analyze time series data. Mann-Kendall statistical test applied detect trends additional statistics computed like Sen-Theil slope estimator.","code":""},{"path":"/reference/process_trend.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"process_trend — process_trend","text":"","code":"process_trend(   dataEX,   MK_level = 0.1,   time_dependency_option = \"INDE\",   suffix = NULL,   suffix_delimiter = \"_\",   to_normalise = FALSE,   metaEX = NULL,   extreme_take_not_signif_into_account = TRUE,   extreme_take_only_series = NULL,   extreme_by_suffix = TRUE,   period_trend = NULL,   period_change = NULL,   extreme_prob = 0.01,   show_advance_stat = FALSE,   dev = FALSE,   verbose = FALSE,   verbose_stat = FALSE )"},{"path":"/reference/process_trend.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"process_trend — process_trend","text":"dataEX Input data format tibble tibble package. needs : one column Date regularly spaced unique time serie. one time serie, least one column needs character string names time series order identify . one column identifier given, used order identify unique time serie. least one column numeric (logical) process variable extraction perform. numerical column can leave useless, suppressed. tibble output process_extraction() function kind wanted input data. MK_level numeric Mann-Kendall test significance level 0 1. Default 0.1. time_dependency_option character string handling temporal dependence Mann-Kendall test. Possible values : \"INDE\", assume independence (.e. standard MK test) \"AR1\", assumes AR1 short-term dependence structure (.e. Hamed Rao's version MK test) \"LTP\", assume long-term persistence (.e. Hamed's version MK test) suffix character string vector representing suffixes appended column names extracted variables. See process_extraction() info. Default NULL. suffix_delimiter character string specifies delimiter use variable name suffix NULL. default \"_\". to_normalise named logical vector indicating whether variable's trend normalised. TRUE performs normalisation, FALSE nothing. vector must length one length number numeric (logical) variables dataEX, names specifying value corresponds variable. Default 'FALSE'. metaEX One outputs CARD_extraction function contains metadata normalisation process. Default NULL. supplied, normalisation information used instead settings provided to_normalise variable. extreme_take_not_signif_into_account logical Whether consider non-significant trends computation extreme trends. Default TRUE. extreme_take_only_series character string vector names time series used computing extreme trends. Default NULL, includes available series. extreme_by_suffix logical TRUE, extreme trends computed across separate sets trend values variable suffix. FALSE, extreme trends variable used without considering suffixes. Default TRUE. period_trend vector two dates (two unambiguous character strings can coerced dates) restrict period analysis. example, can c(\"1950-01-01\", \"2020-12-31\") select data 1st January 1950 end December 2020. default option period_trend=NULL, considers available data time serie. period_change developpement list two vectors two dates (two unambiguous character strings can coerced dates) restrict two period change analysis. example, can list(c(\"1950-01-01\", \"1999-12-31\"), c(\"2000-01-01\", \"2020-12-31\")). default option period_change=NULL, analysis. extreme_prob numeric probability identifying extreme trends using quantiles. Default 0.01, computed extremes based quantile 0.01 0.99. show_advance_stat logical Whether display advanced statistical details. Default FALSE. dev logical TRUE, development mode enabled. Default FALSE. verbose logical Whether print intermediate messages. Default FALSE. verbose_stat logical Whether print detailed statistical messages. Default FALSE.","code":""},{"path":"/reference/process_trend.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"process_trend — process_trend","text":"tibble trend analysis results, including trend coefficients statistical significance variables. precisely, returned trendEX tibble contains following columns : * : idenfiant time series variable_en : name english variables level : see MK_level H : result Mann-Kendall trend test. TRUE trend detected type error MK_level (trust 1-MK_level). FALSE, trend detected type error MK_level. p: p-value indicating statistical significance Mann-Kendall trend test. : -Seil slope estimator gives approximation trend coefficient. WARNING : value always return even Mann-Kendall trend test significant. b : ordinate origin sort can trace `Y = * X + b period_trend : information period analyse trend mean_period_trend : average value variable along period_trend usefull normalisation (NA to_normalise FALSE variable). a_normalise : value normalised mean_period_trend. a_normalise_min : minimum a_normalise values according selection made extreme_take_not_signif_into_account, extreme_take_only_series extreme_by_suffix. a_normalise_max : a_normalise_min maximum values. suffix argument used, column added : variable_no_suffix_en :  name english variables without suffixes also, period_change argument filled , columns added : period_change : information period analyse change break mean_period_change : change : change_min : change_max :","code":""},{"path":[]},{"path":"/reference/process_trend.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"process_trend — process_trend","text":"","code":"## Creation of random data set set.seed(99) Start = as.Date(\"2000-02-01\") End = as.Date(\"2010-04-04\") Date = seq.Date(Start, End, by=\"day\")  # First time serie data_1 = dplyr::tibble(time=Date,                        X_state1=as.numeric(Date) +                            rnorm(length(Date), 1e4, 1e3),                        X_state2=seq(1, length(Date))/1e2 +                            rnorm(length(Date), 0, 1),                        id=\"serie 1\") data_1$X_state2[round(runif(500, 1, nrow(data_1)))] = NA  # Second time serie data_2 = dplyr::tibble(time=Date,                        X_state1=as.numeric(Date) +                            rnorm(length(Date), 1e4, 1e3),                        X_state2=seq(1, length(Date))/1e2 +                            rnorm(length(Date), 0, 1),                        id=\"serie 2\") data_2$X_state2[round(runif(1000, 1, nrow(data_2)))] = NA  # Final data for testing data = dplyr::bind_rows(data_1, data_2)  ## Extraction of the yearly average of daily value. dataEX = process_extraction(data=data,                    funct=list(XA_state1=mean),                    funct_args=list(\"X_state1\", na.rm=TRUE),                    time_step=\"year\")  dataEX = process_extraction(data=data,                             funct=list(XA=mean,                                        XX=max),                             funct_args=list(list(\"X\", na.rm=TRUE),                                             list(\"X\", na.rm=TRUE)),                             suffix=c(\"state1\", \"state2\"),                             time_step=\"year\")  ## Trend test # The direct application does not take care of possible grouped # variables by suffix for extremes trends values. trendEX1 = process_trend(dataEX,                          to_normalise=TRUE) #> Warning: 'to_normalise' is a unique value so it will be repeated for all the variables : XA_state1, XX_state1, XA_state2, XX_state2 print(trendEX1, width=Inf) #> # A tibble: 8 × 12 #>   id      variable_en level H             p      a       b period_trend #>   <chr>   <chr>       <dbl> <lgl>     <dbl>  <dbl>   <dbl> <list>       #> 1 serie 1 XA_state1     0.1 TRUE  0.0000262 366.   10168.  <date [2]>   #> 2 serie 1 XA_state2     0.1 TRUE  0.0000262   3.64  -108.  <date [2]>   #> 3 serie 1 XX_state1     0.1 TRUE  0.000186  391.   12367.  <date [2]>   #> 4 serie 1 XX_state2     0.1 TRUE  0.0000262   3.52   -99.8 <date [2]>   #> 5 serie 2 XA_state1     0.1 TRUE  0.0000262 366.   10155.  <date [2]>   #> 6 serie 2 XA_state2     0.1 TRUE  0.0000262   3.63  -107.  <date [2]>   #> 7 serie 2 XX_state1     0.1 TRUE  0.000186  404.   11774.  <date [2]>   #> 8 serie 2 XX_state2     0.1 TRUE  0.0000262   3.57  -102.  <date [2]>   #>   mean_period_trend a_normalise a_normalise_min a_normalise_max #>               <dbl>       <dbl>           <dbl>           <dbl> #> 1           22959.         1.59            1.59            1.59 #> 2              19.7       18.5            18.5            18.5  #> 3           26063.         1.50            1.50            1.56 #> 4              23.4       15.0            15.0            15.4  #> 5           22967.         1.59            1.59            1.59 #> 6              19.6       18.5            18.5            18.5  #> 7           25897.         1.56            1.50            1.56 #> 8              23.1       15.4            15.0            15.4   # More complicated case with the use of 'period_change' and customs # normalisation info trendEX2 =     process_trend(dataEX,                   suffix=c(\"state1\", \"state2\"),                   suffix_delimiter=\"_\",                   to_normalise=c(\"XA_state1\"=FALSE,                                  \"XA_state2\"=FALSE,                                  \"XX_state1\"=TRUE,                                  \"XX_state2\"=TRUE),                   extreme_take_only_series=NULL,                   extreme_by_suffix=FALSE,                   period_change=list(c(as.Date(\"2000-01-01\"),                                        as.Date(\"2005-01-01\")),                                      c(as.Date(\"2006-01-01\"),                                        as.Date(\"2010-01-01\")))) print(trendEX2, width=Inf) #> # A tibble: 8 × 18 #>   id      variable_en variable_no_suffix_en level H             p      a       b #>   <chr>   <chr>       <chr>                 <dbl> <lgl>     <dbl>  <dbl>   <dbl> #> 1 serie 1 XA_state1   XA                      0.1 TRUE  0.0000262 366.   10168.  #> 2 serie 1 XA_state2   XA                      0.1 TRUE  0.0000262   3.64  -108.  #> 3 serie 1 XX_state1   XX                      0.1 TRUE  0.000186  391.   12367.  #> 4 serie 1 XX_state2   XX                      0.1 TRUE  0.0000262   3.52   -99.8 #> 5 serie 2 XA_state1   XA                      0.1 TRUE  0.0000262 366.   10155.  #> 6 serie 2 XA_state2   XA                      0.1 TRUE  0.0000262   3.63  -107.  #> 7 serie 2 XX_state1   XX                      0.1 TRUE  0.000186  404.   11774.  #> 8 serie 2 XX_state2   XX                      0.1 TRUE  0.0000262   3.57  -102.  #>   period_trend mean_period_trend a_normalise a_normalise_min a_normalise_max #>   <list>                   <dbl>       <dbl>           <dbl>           <dbl> #> 1 <date [2]>                NA        366.              3.63           366.  #> 2 <date [2]>                NA          3.64            3.63           366.  #> 3 <date [2]>             26063.         1.50            1.50            15.4 #> 4 <date [2]>                23.4       15.0             1.50            15.4 #> 5 <date [2]>                NA        366.              3.63           366.  #> 6 <date [2]>                NA          3.63            3.63           366.  #> 7 <date [2]>             25897.         1.56            1.50            15.4 #> 8 <date [2]>                23.1       15.4             1.50            15.4 #>   period_change mean_period_change  change change_min change_max #>   <list>        <list>               <dbl>      <dbl>      <dbl> #> 1 <list [2]>    <dbl [2]>          1985.        19.8       2025. #> 2 <list [2]>    <dbl [2]>            19.8       19.8       2025. #> 3 <list [2]>    <dbl [2]>             8.33       7.68       132. #> 4 <list [2]>    <dbl [2]>           132.         7.68       132. #> 5 <list [2]>    <dbl [2]>          2026.        19.8       2025. #> 6 <list [2]>    <dbl [2]>            19.8       19.8       2025. #> 7 <list [2]>    <dbl [2]>             7.66       7.68       132. #> 8 <list [2]>    <dbl [2]>           132.         7.68       132."},{"path":"/reference/randomizedNormalScore.html","id":null,"dir":"Reference","previous_headings":"","what":"Randomized Normal Score — randomizedNormalScore","title":"Randomized Normal Score — randomizedNormalScore","text":"Randomized Normal Score transformation","code":""},{"path":"/reference/randomizedNormalScore.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Randomized Normal Score — randomizedNormalScore","text":"","code":"randomizedNormalScore(x)"},{"path":"/reference/randomizedNormalScore.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Randomized Normal Score — randomizedNormalScore","text":"x numeric, data","code":""},{"path":"/reference/randomizedNormalScore.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Randomized Normal Score — randomizedNormalScore","text":"normal-score-transformed series","code":""},{"path":"/reference/randomizedNormalScore.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Randomized Normal Score — randomizedNormalScore","text":"","code":"if (FALSE) { # \\dontrun{ data(nhtemp) # Average Yearly Temperatures in New Haven z = randomizedNormalScore(x=nhtemp) par(mfrow = c(1, 2)) plot(nhtemp, type='b');plot(z, type='b') } # }"},{"path":"/reference/sourceProcess.html","id":null,"dir":"Reference","previous_headings":"","what":"sourceProcess — sourceProcess","title":"sourceProcess — sourceProcess","text":"Allows read CARD formatism convert Process variable explain step necessary extraction process_extraction().","code":""},{"path":"/reference/sourceProcess.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"sourceProcess — sourceProcess","text":"","code":"sourceProcess(path, default = NULL)"},{"path":"/reference/sourceProcess.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"sourceProcess — sourceProcess","text":"path character string path CARD file. default default process loaded Process_default = sourceProcess(file.path(CARD_path, \"__default__.R\")) load default parameters every extraction process. Default NULL.","code":""},{"path":"/reference/sourceProcess.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"sourceProcess — sourceProcess","text":"Process variable list general parameters, sub list extraction process parameters.","code":""},{"path":[]},{"path":"/reference/sourceProcess.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"sourceProcess — sourceProcess","text":"","code":"if (FALSE) { # \\dontrun{ Process_default = sourceProcess(path=\"path/to/CARD/__default__.R\") Process = sourceProcess(path=\"path/to/CARD/script.R\",                         default=Process_default) } # }"}]
